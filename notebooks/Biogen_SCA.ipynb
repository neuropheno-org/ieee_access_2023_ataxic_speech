{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3788035f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "sys.path.append('../../')\n",
    "\n",
    "from script.Model_run import Speech_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7665c200",
   "metadata": {},
   "outputs": [],
   "source": [
    "def monkey_patch_openpyxl():\n",
    "    '''Openpyxl has a bug with workbooks that have wrong cell styling information.\n",
    "    Monkey patch the library so it can handle these types of workbooks.'''\n",
    "    from openpyxl.worksheet import _reader\n",
    "    from openpyxl.cell import Cell\n",
    "    def bind_cells(self):\n",
    "        for idx, row in self.parser.parse():\n",
    "            for cell in row:\n",
    "                try:\n",
    "                    style = self.ws.parent._cell_styles[cell['style_id']]\n",
    "                except:  ## This is the patch, original doesn't have a try/except here\n",
    "                    style = None\n",
    "                c = Cell(self.ws, row=cell['row'], column=cell['column'], style_array=style)\n",
    "                c._value = cell['value']\n",
    "                c.data_type = cell['data_type']\n",
    "                self.ws._cells[(cell['row'], cell['column'])] = c\n",
    "        self.ws.formula_attributes = self.parser.array_formulae\n",
    "        if self.ws._cells:\n",
    "            self.ws._current_row = self.ws.max_row # use cells not row dimensions\n",
    "\n",
    "    _reader.WorksheetReader.bind_cells = bind_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6b150d",
   "metadata": {},
   "outputs": [],
   "source": [
    "monkey_patch_openpyxl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e575e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Directory where the data are stored\n",
    "data_home_dir = '/home/kvattis/Dropbox (Partners HealthCare)/Data_Raw_Biogen_SCA/'\n",
    "#Most recent Patient_info file\n",
    "Patient_info_recent = 'Subjects_BiogenSCA_with_questionnaires_2022_07_20_converted.xlsx'\n",
    "#Location and name of the output file\n",
    "outputfile_address = '/home/kvattis/Desktop/BiogenSca_outputs_2022_07_22.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4640f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the models\n",
    "speech_analyzer = Speech_analysis(print_on = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f30240",
   "metadata": {},
   "source": [
    "# Biogen SCA study"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe6bf7c",
   "metadata": {},
   "source": [
    "This notebook runs the speech classification and severity estimation on the Biogen SCA study cohort and saves the output in a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027269e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#survey_lex = pd.read_csv(data_home_dir + 'Biogen_SCA_Speech_Data/' + 'surveylex_questionIDs.csv',encoding='latin1')\n",
    "survey_lex = pd.read_excel(data_home_dir + 'Biogen_SCA_Speech_Data/' + 'surveylex_questionIDs.xlsx',engine='openpyxl')\n",
    "taskslist = survey_lex['question'].unique()\n",
    "output = pd.DataFrame(columns = ['Date','subject_id','Neuropheno_ID','Bars','Bars_Speech','Sex','Diagnosis','DoB','Samples_no','Prob_AT_tf_grad', 'Bars_Speech_pred_t','Bars_Total_pred_t'])\n",
    "                      \n",
    "for tt in  taskslist: \n",
    "    if tt not in [\"la_la_la\",\"go_go_go\",\"me_me_me\", \"lalala\", \"gogogo\", \"mememe\",\"papapa\"]:\n",
    "        continue\n",
    "    print(tt)\n",
    "    pd.set_option('display.max_columns', 4)\n",
    "    np.dtype(np.int16)\n",
    "    task = str(tt)\n",
    "    task_dir = str(tt)\n",
    "    \n",
    "    #loading the session file names and patient info\n",
    "    \n",
    "    study_name = 'Biogen_SCA_Speech_Data'\n",
    "    study_dir = data_home_dir + 'Biogen_SCA_Speech_Data/'\n",
    "    #survey_lex = pd.read_csv(study_dir + 'surveylex_questionIDs.csv',encoding='latin1')\n",
    "    survey_lex = pd.read_excel(study_dir + 'surveylex_questionIDs.xlsx',engine='openpyxl')\n",
    "\n",
    "    survey_response_A = pd.read_csv(study_dir + 'surveyA-responses-summary.csv',encoding='latin1') #pd.read_excel(study_dir + 'surveyA-responses-summary.xlsx',engine='openpyxl')\n",
    "    survey_response_B = pd.read_csv(study_dir + 'surveyB-responses-summary.csv',encoding='latin1') #pd.read_excel(study_dir + 'surveyB-responses-summary.xlsx',engine='openpyxl')\n",
    "    survey_response_C = pd.read_csv(study_dir + 'surveyC-responses-summary.csv',encoding='latin1') #pd.read_excel(study_dir + 'surveyC-responses-summary.xlsx',engine='openpyxl')\n",
    "    survey_response_D = pd.read_csv(study_dir + 'surveyD-responses-summary.csv',encoding='latin1') #pd.read_excel(study_dir + 'surveyD-responses-summary.xlsx',engine='openpyxl')\n",
    "    \n",
    "    survey_response = pd.concat([survey_response_A, survey_response_B, survey_response_C, survey_response_D], ignore_index=True)\n",
    "    \n",
    "    survey_submissions_A = pd.read_csv(study_dir + 'surveyA-submissions-summary.csv',encoding='latin1') #pd.read_excel(study_dir + 'surveyA-submissions-summary.xlsx',engine='openpyxl')\n",
    "    survey_submissions_B = pd.read_csv(study_dir + 'surveyB-submissions-summary.csv',encoding='latin1') #pd.read_excel(study_dir + 'surveyB-submissions-summary.xlsx',engine='openpyxl')\n",
    "    survey_submissions_C = pd.read_csv(study_dir + 'surveyC-submissions-summary.csv',encoding='latin1') #pd.read_excel(study_dir + 'surveyC-submissions-summary.xlsx',engine='openpyxl')\n",
    "    survey_submissions_D = pd.read_csv(study_dir + 'surveyD-submissions-summary.csv',encoding='latin1') #pd.read_excel(study_dir + 'surveyD-submissions-summary.xlsx',engine='openpyxl')\n",
    "    \n",
    "\n",
    "    survey_submissions = pd.concat([survey_submissions_A, survey_submissions_B, survey_submissions_C, survey_submissions_D], ignore_index=True)\n",
    "    survey_submissions['Your participant ID:'] = pd.to_numeric(survey_submissions['Your participant ID:'], errors='coerce',downcast='integer')\n",
    "    survey_submissions = survey_submissions[(survey_submissions['Your participant ID:'] > 30000) &(survey_submissions['Your participant ID:'] < 40000)]\n",
    "    \n",
    "    _Patient_info = pd.read_csv(data_home_dir + 'Subjects/Subjects_BiogenSCA_version2.csv',encoding='latin1')\n",
    "    _Patient_info_ = _Patient_info.loc[:,['subject_id','neuropheno_id','diagnosis','bars_total_excl_miss_1','bars_total_excl_miss_2', 'bars_speech_1', 'bars_speech_2','sex']]\n",
    "\n",
    "    Patient_info = pd.read_excel(data_home_dir + 'Subjects/' + Patient_info_recent,engine='openpyxl')\n",
    "    Patient_info_ = Patient_info.loc[:,['subject_id','neuropheno_id','diagnosis','bars_total_excl_miss_1','bars_total_excl_miss_2', 'bars_speech_1', 'bars_speech_2','sex','dob']]\n",
    "    \n",
    "    #Check that the neurphone_ids are included\n",
    "    for i in _Patient_info_['subject_id']:\n",
    "        Patient_info_.loc[Patient_info_['subject_id'] == i,'neuropheno_id']  = _Patient_info_.loc[_Patient_info_['subject_id'] == i,'neuropheno_id']\n",
    "    \n",
    "    survey_lex_ = survey_lex.loc[:,['questionId','question']]\n",
    "    survey_response_ = survey_response.loc[:,['sampleId','questionId', 'sessionId','createdDate']]\n",
    "    survey_response_['createdDate'] = survey_response_['createdDate'].apply(lambda x: x[0:4] + '_' + x[5:7] + '_' + x[8:10] )\n",
    "    survey_submissions_ = survey_submissions.loc[:,['sessionId','Your participant ID:']]\n",
    "    survey_submissions_ = survey_submissions_.rename(columns={\"Your participant ID:\": \"subject_id\"})\n",
    "    df = pd.merge(pd.merge(pd.merge(survey_response_,survey_lex_,on='questionId'), survey_submissions_, on = 'sessionId'),Patient_info_, on = 'subject_id')\n",
    "    df.dropna(subset = [\"sampleId\"], inplace=True)\n",
    "\n",
    "    df_task = df.loc[df['question'] == task][['sampleId','subject_id','neuropheno_id','diagnosis','createdDate','bars_total_excl_miss_1','bars_total_excl_miss_2', 'bars_speech_1', 'bars_speech_2','sex']]#, 'age']]\n",
    "    df_task_numpy = df_task.to_numpy()\n",
    "    \n",
    "    list_diagnostic = ['Control', 'Ataxia', 'MSA', 'Other']\n",
    "\n",
    "    \n",
    "    #Going over all the files for the task\n",
    "    list_names = []\n",
    "    for entry in df_task_numpy:\n",
    "        file_name = entry[0]\n",
    "        ID = str(int(entry[1]))\n",
    "\n",
    "        if  not np.isnan(entry[2]):\n",
    "            Neur_phen_id = str(int(entry[2]))\n",
    "        else:\n",
    "            Neur_phen_id = ID\n",
    "        \n",
    "        diagn = entry[3]\n",
    "        date = entry[4]\n",
    "        Date = date[:4] + date[5:7] + date[8:]\n",
    "        bars_total = (entry[5] + entry[6])/2.\n",
    "        bars_speech = (entry[7] + entry[8])/2./10.\n",
    "        sex = entry[9]\n",
    "        #age = entry[10]\n",
    "        \n",
    "        #Reading the file if it exist\n",
    "        path_to_file = study_dir + ID + '_' + date + '_A/' + file_name + '.wav'\n",
    "        path_to_file_flag = 0\n",
    "        \n",
    "        if os.path.exists(path_to_file):\n",
    "            path_to_file_flag = 1 \n",
    "        \n",
    "        if not os.path.exists(path_to_file):\n",
    "            path_to_file = study_dir + ID + '_' + date + '_B/' + file_name + '.wav'\n",
    "        else:\n",
    "            path_to_file_flag = 1\n",
    "        \n",
    "        if not os.path.exists(path_to_file):\n",
    "            path_to_file = study_dir + ID + '_' + date + '_C/' + file_name + '.wav'\n",
    "        else:\n",
    "            path_to_file_flag = 1\n",
    "            \n",
    "        if not os.path.exists(path_to_file):\n",
    "            path_to_file = study_dir + ID + '_' + date + '_D/' + file_name + '.wav'\n",
    "        else:\n",
    "            path_to_file_flag = 1    \n",
    "        \n",
    "        if path_to_file_flag == 0: continue;\n",
    "            \n",
    "        #Assign label\n",
    "        if diagn == 0:\n",
    "            #diagn = 'Control'\n",
    "            label = 0\n",
    "        elif diagn == 1:\n",
    "            #diagn = 'Ataxia'\n",
    "            label = 1\n",
    "        elif diagn == 2:\n",
    "            #diagn = 'Ataxia'\n",
    "            label = 1\n",
    "        elif diagn == 3:\n",
    "            #diagn = 'Ataxia'\n",
    "            label = 1\n",
    "        elif diagn == 7:\n",
    "            #diagn = 'MSA'\n",
    "            label = 7\n",
    "        else:\n",
    "            #diagn = 'Other'\n",
    "            label = 5\n",
    "        \n",
    "        #Include only Controls and SCA patients\n",
    "        #if label not in [0,1]:\n",
    "        #    continue\n",
    "        \n",
    "        #Set the bars to 0 for all controls\n",
    "        if label == 0:\n",
    "            bars_total = 0\n",
    "            bars_speech = 0 \n",
    "        \n",
    "        #Run the file through the models\n",
    "        if Neur_phen_id == ID:\n",
    "            speech_analyzer.load(path_to_file, Neur_phen_id)\n",
    "            no_samples = speech_analyzer.sample_size_s\n",
    "            Neur_phen_id = None\n",
    "        else:\n",
    "            speech_analyzer.load(path_to_file,Neur_phen_id)\n",
    "            no_samples = speech_analyzer.sample_size_s\n",
    "        \n",
    "        if no_samples == 0:\n",
    "            print(ID)\n",
    "            continue\n",
    "        \n",
    "        #Store the model output\n",
    "        output = output.append({'Date' : Date, 'subject_id' : ID, 'Neuropheno_ID' : Neur_phen_id, 'Bars': bars_total, 'Bars_Speech':bars_speech, 'Sex': sex, 'Diagnosis': diagn,'Samples_no' : speech_analyzer.sample_size_s, 'Prob_AT_tf_grad': speech_analyzer.classify(),\n",
    "                               'Bars_Speech_pred_t': speech_analyzer.BARS_speech(), 'Bars_Total_pred_t': speech_analyzer.BARS_total()}, \n",
    "                ignore_index = True)\n",
    "\n",
    "#Take the median of all samples by subject and session\n",
    "output = output.astype(float).groupby(['Date','subject_id'], as_index = False).median().sort_values(by=['subject_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eec6db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_analyzer.plot_wav()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370e136b",
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_analyzer.play_audio_nr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb00daea",
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_analyzer.plot_mel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede5f8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 10)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "np.dtype(np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6675d343",
   "metadata": {},
   "outputs": [],
   "source": [
    "output['subject_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d197b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in output['subject_id'].unique():\n",
    "    output.loc[output['subject_id'] == i,'DoB'] = pd.to_datetime(Patient_info_.loc[Patient_info_['subject_id'] == i,'dob'].item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1909fe3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output[['subject_id','Bars', 'Bars_Speech', 'Samples_no', 'Diagnosis','Prob_AT_tf_grad', 'Bars_Speech_pred_t','Bars_Total_pred_t']].head(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a588056",
   "metadata": {},
   "outputs": [],
   "source": [
    "output[output['subject_id']>30030][['subject_id','Bars', 'Bars_Speech', 'Samples_no', 'Diagnosis','Prob_AT_tf_grad', 'Bars_Speech_pred_t','Bars_Total_pred_t']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca07118",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv(outputfile_address, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cc4aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_sca1 = output[output['Diagnosis'] == 1]\n",
    "output_sca2 = output[output['Diagnosis'] == 2]\n",
    "output_sca3 = output[output['Diagnosis'] == 3]\n",
    "output_c = output[output['Diagnosis'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d70660",
   "metadata": {},
   "source": [
    "Below there some sanity check plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9897ef55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26d95f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.scatter(output_c['Bars_Speech'], output_c['Prob_AT_tf_grad'], c = 'b' , marker = 'x')\n",
    "ax.scatter(output_sca1['Bars_Speech'], output_sca1['Prob_AT_tf_grad'], c = 'k' , marker = 'x')\n",
    "ax.scatter(output_sca2['Bars_Speech'], output_sca2['Prob_AT_tf_grad'], c = 'g' , marker = 'x')\n",
    "ax.scatter(output_sca3['Bars_Speech'], output_sca3['Prob_AT_tf_grad'], c = 'r' , marker = 'x')\n",
    "plt.xlim([-0.2, 4])\n",
    "plt.ylim([-0.05, 1.05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b943821",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "plt.plot([0,4],[0,4])\n",
    "\n",
    "ax.scatter(output_sca1['Bars_Speech'], output_sca1['Bars_Speech_pred_t'], c = 'k' , marker = 'x')\n",
    "ax.scatter(output_sca2['Bars_Speech'], output_sca2['Bars_Speech_pred_t'], c = 'g' , marker = 'x')\n",
    "ax.scatter(output_sca3['Bars_Speech'], output_sca3['Bars_Speech_pred_t'], c = 'r' , marker = 'x')\n",
    "ax.scatter(output_c['Bars_Speech'], output_c['Bars_Speech_pred_t'], c = 'b' , marker = 'x')\n",
    "\n",
    "plt.xlim([-0.2, 4])\n",
    "plt.ylim([-0.05, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb6193c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "plt.plot([0,30],[0,30])\n",
    "ax.scatter(output_c['Bars'], output_c['Bars_Total_pred_t'], c = 'b' , marker = 'x')\n",
    "ax.scatter(output_sca1['Bars'], output_sca1['Bars_Total_pred_t'], c = 'k' , marker = 'x')\n",
    "ax.scatter(output_sca2['Bars'], output_sca2['Bars_Total_pred_t'], c = 'g' , marker = 'x')\n",
    "ax.scatter(output_sca3['Bars'], output_sca3['Bars_Total_pred_t'], c = 'r' , marker = 'x')\n",
    "plt.xlim([-0.2, 30])\n",
    "plt.ylim([-0.05, 30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb2e559",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70020259",
   "metadata": {},
   "outputs": [],
   "source": [
    "Patient_info = pd.read_excel(data_home_dir + 'Subjects/Subjects_BiogenSCA_with_questionnaires_2022_07_20_converted.xlsx',engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5453e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Patient_info.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2b24d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Patient_info[['record_id','diagnosis']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25421fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#survey_response_A = pd.read_excel(study_dir + 'surveyA-submissions-summary.xlsx',engine='openpyxl')\n",
    "pd.read_csv(study_dir + 'surveyA-submissions-summary.csv',encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760f866c",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_response_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc860b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
