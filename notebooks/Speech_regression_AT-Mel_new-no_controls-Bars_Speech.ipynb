{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c3ba65e",
   "metadata": {},
   "source": [
    "# Speech classifier for NDs using RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0819eac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basics\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import csv\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import scipy.stats as stats\n",
    "import scipy.signal as signal\n",
    "from scipy.stats import shapiro,normaltest,kstest,uniform\n",
    "import seaborn as sns\n",
    "import matplotlib.colors as colors\n",
    "sys.path.append('../../')\n",
    "\n",
    "#sklearn \n",
    "from multiprocessing import cpu_count\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix,f1_score, roc_curve,auc, roc_auc_score,ConfusionMatrixDisplay\n",
    "\n",
    "#Pytorch\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch. optim.lr_scheduler import _LRScheduler\n",
    "import torch.optim as optim\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "import torchvision.models as models\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "#Pytorch lightning\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks.model_checkpoint import ModelCheckpoint\n",
    "from pytorch_lightning.metrics.functional import accuracy\n",
    "from pytorch_lightning import Trainer\n",
    "import torchmetrics\n",
    "\n",
    "#models\n",
    "from script.models import CNN_short_fc,CNN_short_fc_wide,FC_Resnet_\n",
    "\n",
    "#utils\n",
    "from script.utils import KFoldCVDataModule, CVTrainer, PadImage_inf, ImbalancedDatasetSampler\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "#Captum\n",
    "from captum.attr import IntegratedGradients\n",
    "from captum.attr import GradientShap\n",
    "from captum.attr import Occlusion\n",
    "from captum.attr import NoiseTunnel\n",
    "from captum.attr import visualization as viz\n",
    "from matplotlib.colors import LinearSegmentedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964ab130",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "torch.manual_seed(42)\n",
    "pd.set_option('float_format', '{:f}'.format)\n",
    "#torch.backends.cudnn.benchmark = True\n",
    "%matplotlib inline\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "default_cmap = LinearSegmentedColormap.from_list('custom blue', \n",
    "                                                 [(0, '#ffffff'),\n",
    "                                                  (0.25, '#000000'),\n",
    "                                                  (1, '#000000')], N=256)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd245a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_colormap(cmap, minval=0.0, maxval=1.0, n=100):\n",
    "    new_cmap = colors.LinearSegmentedColormap.from_list(\n",
    "        'trunc({n},{a:.2f},{b:.2f})'.format(n=cmap.name, a=minval, b=maxval),\n",
    "        cmap(np.linspace(minval, maxval, n)))\n",
    "    return new_cmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5d850b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter definition\n",
    "epochs = 100 # no of epochs\n",
    "model_size_ = '18'\n",
    "Batch_Size = 128 #batch size\n",
    "no_feutures = 128 #no of features per entry\n",
    "training_on = True\n",
    "root_dir = '/home/kvattis/Documents/data/'\n",
    "train_csv_file = root_dir + 'train_dataset_control_AT_Mel_Spec_2022_noise_red2_v4.csv'\n",
    "val_csv_file = root_dir + 'val_dataset_control_AT_Mel_Spec_2022_noise_red2_v4.csv'\n",
    "train_demo_csv_file = root_dir +'train_demo_Mel_Spec_small_cnn_nr2_v4.csv'\n",
    "val_demo_csv_file = root_dir + 'val_demo_Mel_Spec_small_cnn_nr2_v4.csv'\n",
    "parent_directory = '/home/kvattis/Documents/speech_analysis/'\n",
    "checkpoint_directory = parent_directory + 'checkpoints/ResNet_grad_reg/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93662ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_class = [3487,8145]\n",
    "weights = [1/x for x in n_class]\n",
    "weights = [ww/np.sum(weights) for ww in weights]\n",
    "#weights = [0.75, 0.25]\n",
    "class_weights = torch.FloatTensor(weights)\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735b66ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scale(X, range_=(0, 1)):\n",
    "    mi, ma = range_\n",
    "    X_min = -50\n",
    "    X_max = 50\n",
    "    #X_std = (X - X.min()) / (X.max() - X.min())\n",
    "    X_std = (X - X_min) / (X_max - X_min)\n",
    "    X_scaled = X_std * (ma - mi) + mi\n",
    "    return X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f233ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augm(spec):\n",
    "    freq_mask_param = 25\n",
    "    time_mask_param = 10\n",
    "    \n",
    "    masking_T = T.TimeMasking(time_mask_param=time_mask_param)\n",
    "    masking_f = T.FrequencyMasking(freq_mask_param = freq_mask_param)\n",
    "\n",
    "    spec = masking_T(spec)\n",
    "    spec = masking_f(spec)\n",
    "    \n",
    "    return spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb405bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup_data(x, y, alpha=1.0):\n",
    "    '''Returns mixed inputs, pairs of targets, and lambda'''\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "\n",
    "    batch_size = x.size()[0]\n",
    "    \n",
    "    index = torch.randperm(batch_size)\n",
    "\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e8f657",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fa8afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transforms_train(spec,l):\n",
    "    upper_limit = spec.shape[1]\n",
    "    if l == 0:\n",
    "        random_size = random.randint(25,upper_limit)\n",
    "        transforms_ = transforms.Compose([transforms.RandomCrop((random_size, 128)),transforms.Resize((100, 100))])\n",
    "    else:\n",
    "        random_size = random.randint(35,upper_limit)\n",
    "        transforms_ = transforms.Compose([transforms.RandomCrop((random_size, 128)),transforms.Resize((100, 100))])\n",
    "    spec = transforms_(spec)\n",
    "    return spec\n",
    "\n",
    "def transforms_val(spec,l):\n",
    "    transforms_resize = transforms.Resize((100, 100))\n",
    "    spec = transforms_resize(spec)\n",
    "    return spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bc3fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_std(X, mean = -0.0005, std = 0.0454):\n",
    "    X_scaled = (X - mean)/ std\n",
    "    return X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5746ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plain(spec):\n",
    "    return spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbef61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def groupby_mean(value:torch.Tensor, labels:torch.LongTensor) -> (torch.Tensor, torch.LongTensor):\n",
    "    \"\"\"Group-wise average for (sparse) grouped tensors\n",
    "\n",
    "    Args:\n",
    "        value (torch.Tensor): values to average (# samples, latent dimension)\n",
    "        labels (torch.LongTensor): labels for embedding parameters (# samples,)\n",
    "\n",
    "    Returns: \n",
    "        result (torch.Tensor): (# unique labels, latent dimension)\n",
    "        new_labels (torch.LongTensor): (# unique labels,)\n",
    "\n",
    "    Examples:\n",
    "        >>> samples = torch.Tensor([\n",
    "                             [0.15, 0.15, 0.15],    #-> group / class 1\n",
    "                             [0.2, 0.2, 0.2],    #-> group / class 3\n",
    "                             [0.4, 0.4, 0.4],    #-> group / class 3\n",
    "                             [0.0, 0.0, 0.0]     #-> group / class 0\n",
    "                      ])\n",
    "        >>> labels = torch.LongTensor([1, 5, 5, 0])\n",
    "        >>> result, new_labels = groupby_mean(samples, labels)\n",
    "\n",
    "        >>> result\n",
    "        tensor([[0.0000, 0.0000, 0.0000],\n",
    "            [0.1500, 0.1500, 0.1500],\n",
    "            [0.3000, 0.3000, 0.3000]])\n",
    "\n",
    "        >>> new_labels\n",
    "        tensor([0, 1, 5])\n",
    "    \"\"\"\n",
    "    uniques = labels.unique().tolist()\n",
    "    labels = labels.tolist()\n",
    "\n",
    "    key_val = {key: val for key, val in zip(uniques, range(len(uniques)))}\n",
    "    val_key = {val: key for key, val in zip(uniques, range(len(uniques)))}\n",
    "\n",
    "    labels = torch.LongTensor(list(map(key_val.get, labels)))\n",
    "\n",
    "    labels = labels.view(labels.size(0), 1).expand(-1, value.size(1))\n",
    "\n",
    "    unique_labels, labels_count = labels.unique(dim=0, return_counts=True)\n",
    "    result = torch.zeros_like(unique_labels.to(device), dtype=value.dtype).scatter_add_(0, labels.to(device), value.to(device))\n",
    "    result = result.to(device) / labels_count.float().unsqueeze(1).to(device)\n",
    "    new_labels = torch.LongTensor(list(map(val_key.get, unique_labels[:, 0].tolist())))\n",
    "    return result.to(device), new_labels.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4673f943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting standard filter requirements.\n",
    "order = 6\n",
    "nyq_freq = 30.0       \n",
    "cutoff_frequency = 7.5#3.667  \n",
    "\n",
    "def butterLow(cutoff, critical, order):\n",
    "    normal_cutoff = float(cutoff) / critical\n",
    "    b, a = signal.butter(order, normal_cutoff, btype='lowpass')\n",
    "    return b, a\n",
    "\n",
    "def butterFilter(data, cutoff_freq, nyq_freq, order):\n",
    "    b, a = butterLow(cutoff_freq, nyq_freq, order)\n",
    "    y = signal.filtfilt(b, a, data)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa16eba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a pytorch Dataset               \n",
    "class SpeechDataset(Dataset):\n",
    "    def __init__(self, csv_file, demo_csv, root_dir,transform):\n",
    "            \n",
    "        self.file_names = pd.read_csv(csv_file,header = None, names=[\"No\",\"P_ID\", \"Address\",\"Label\",\"Date\"])\n",
    "        self.demo = pd.read_csv(demo_csv, names=[\"No\",\"P_ID\", \"Sex\", \"Bars\",\"Age\",\"Bars_Speech\", \"PDate\"])\n",
    "        self.file_names['Bars'] = self.demo['Bars_Speech']\n",
    "        #self.file_names['Age'] = self.demo['Age']\n",
    "        #self.file_names = self.file_names[self.file_names['Age']<18]\n",
    "        self.file_names.loc[(self.file_names.Label == 0),'Bars']= 0.\n",
    "        #self.file_names = self.file_names[self.file_names.Label == 1] \n",
    "        self.file_names = self.file_names[self.file_names.Bars >= 0] \n",
    "        self.file_names_bars = self.file_names[self.file_names['Bars'].notna()] \n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_names_bars)   \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        address =  os.path.join(self.root_dir,\n",
    "                                self.file_names_bars.iloc[idx, 2])\n",
    "                \n",
    "        df = pd.read_csv(address,header = None)                                                                              \n",
    "        df_ar = df.to_numpy()\n",
    "        df_ar = min_max_scale(df_ar)\n",
    "        \n",
    "        df_ar_t = np.gradient(df_ar, axis = 0)\n",
    "        #df_ar_t = butterFilter(df_ar_t, cutoff_frequency, nyq_freq/2., order = order)\n",
    "        #df_ar_t_p = np.where(df_ar_t > 0, df_ar_t, 0)\n",
    "        #df_ar_t_n = np.abs(np.where(df_ar_t < 0, df_ar_t, 0))\n",
    "        \n",
    "        df_ar_f = np.gradient(df_ar, axis = 1)\n",
    "        #df_ar_f = butterFilter(df_ar_f, cutoff_frequency, nyq_freq/2., order = order)\n",
    "        #df_ar_f_p = np.where(df_ar_f > 0, df_ar_f, 0)\n",
    "        #df_ar_f_n = np.abs(np.where(df_ar_f < 0, df_ar_f, 0))\n",
    "\n",
    "        #df_ar = np.stack((df_ar_t_p,df_ar_t_n,df_ar_f_p,df_ar_f_n), axis=0)\n",
    "        df_ar = np.stack((df_ar_t,df_ar_f), axis=0)\n",
    "        \n",
    "        #df_ar_t = global_std(df_ar_t)\n",
    "        #data = torch.Tensor(df_ar_t.copy())\n",
    "        data = torch.Tensor(df_ar.copy())\n",
    "        \n",
    "        label_ = self.file_names_bars.iloc[idx, 3]\n",
    "        label = torch.LongTensor([label_])\n",
    "        p_id = self.file_names_bars.iloc[idx, 1]\n",
    "        adr_id = int(str(p_id) + str(self.file_names_bars.iloc[idx, 4]))\n",
    "        adr_id = torch.LongTensor([adr_id])\n",
    "        bars = self.file_names_bars.iloc[idx, 5]/4.0\n",
    "        bars = torch.DoubleTensor([bars])\n",
    "        #bars_cat = np.where(bars < 0.5, 0,  np.where(bars < 1.5, 1,  np.where(bars < 2.5, 2,  np.where(bars < 3.5, 3, 4))))\n",
    "        #bars_cat = torch.DoubleTensor([bars])\n",
    "\n",
    "        #data = torch.unsqueeze(data, 0)\n",
    "        if self.transform:\n",
    "            data = self.transform(data,label_)#self.transform(data.T)\n",
    "            #data = data.T\n",
    "            \n",
    "        return data, bars, adr_id, label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e43e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataModule to create the datasets and the dataloaders\n",
    "class SpeechDataModule(pl.LightningDataModule):\n",
    "    def __init__(self,train_dataset, test_dataset, batch_size):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.train_dataset = train_dataset\n",
    "        self.test_dataset = test_dataset\n",
    "\n",
    "        self.dataloader_kwargs = {'batch_size' : self.batch_size,\n",
    "                             'shuffle' : True,\n",
    "                             'num_workers' : 4,\n",
    "                             'collate_fn' : PadImage_inf()}\n",
    "        \n",
    "    def setup(self,stage=None):\n",
    "        self.train_dataset = self.train_dataset\n",
    "        self.test_dataset = self.test_dataset\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, shuffle = True, batch_size = self.batch_size, num_workers = 8 collate_fn=PadImage_inf())\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size = len(self.test_dataset), shuffle = False, num_workers = 8, collate_fn=PadImage_inf())\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset , batch_size = self.batch_size, shuffle = False, num_workers = 8, collate_fn=PadImage_inf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc58f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup the module  \n",
    "train_dataset = SpeechDataset(train_csv_file, train_demo_csv_file, root_dir, transforms_train)\n",
    "test_dataset = SpeechDataset(val_csv_file, val_demo_csv_file, root_dir, transforms_val)\n",
    "print(len(train_dataset), len(test_dataset))\n",
    "data_module = SpeechDataModule(train_dataset, test_dataset, Batch_Size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5979968a",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(data_module.val_dataloader()))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa70dca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[43][1][0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a448b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[43][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a43f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.display.specshow(train_dataset[10][0][0].numpy().T, x_axis='time', sr=8000, hop_length= 160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492c500a",
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.display.specshow(train_dataset[10][0][3].numpy().T, x_axis='time', sr=8000, hop_length= 160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c52f07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.display.specshow(train_dataset[10][0][1].numpy().T, x_axis='time', sr=8000, hop_length= 160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2731d013",
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.display.specshow(train_dataset[23][0][0].numpy().T, x_axis='time', sr=8000,hop_length= 160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2eb499",
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.display.specshow(train_dataset[23][0][1].numpy().T, x_axis='time', sr=8000,hop_length= 160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c5b117",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[23][0][0].numpy().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a79333c",
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.display.specshow(test_dataset[67][0][0].numpy().T, y_axis='mel', x_axis='s', sr=8000, hop_length= 160)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52510dcb",
   "metadata": {},
   "source": [
    "mean = 0.\n",
    "std = 0.\n",
    "nb_samples = 0.\n",
    "max_ = -1000000\n",
    "min_ = 1000000\n",
    "for data in data_module.train_dataloader():\n",
    "    data = data[0]\n",
    "    batch_samples = data.size(0)\n",
    "    data = data.view(batch_samples, data.size(1), -1)\n",
    "    mean += data.mean(2).sum(0)\n",
    "    std += data.std(2).sum(0)\n",
    "    if data.max() > max_:\n",
    "        max_ = data.max()\n",
    "        \n",
    "    if data.min() < min_:\n",
    "        min_ = data.min()\n",
    "        \n",
    "    nb_samples += batch_samples\n",
    "\n",
    "mean /= nb_samples\n",
    "std /= nb_samples\n",
    "print(mean)\n",
    "print(std)\n",
    "print(max_)\n",
    "print(min_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67d7f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictor class performing all the calculations for loss, backpropagation etc        \n",
    "class Speech_Predictor(pl.LightningModule):\n",
    "    def __init__(self, model_size: int):\n",
    "        super(Speech_Predictor,self).__init__()\n",
    "        self.model = FC_Resnet_(num_layers = 2, num_classes = 1) #CNN_short_fc_wide(n_classes=1, n_channels = 2)\n",
    "        self.criterion = nn.HuberLoss(reduction='mean', delta=0.1) #torch.nn.MSELoss()#\n",
    "        self.MSE = torch.nn.MSELoss()\n",
    "        \n",
    "    def forward(self,x,labels = None, targets_a = None, targets_b = None, lam = None):\n",
    "        output = self.model(x)\n",
    "        loss = 0\n",
    "        if labels is not None:\n",
    "        #    if lam is not None:\n",
    "        #        loss =  mixup_criterion(self.criterion, output, targets_a, targets_b, lam)\n",
    "        #    else:\n",
    "        #        loss = self.criterion(output,labels)\n",
    "        #    return loss, output\n",
    "            loss = self.criterion(output,labels)\n",
    "            return loss, output\n",
    "        else:\n",
    "            return output\n",
    "        \n",
    "        \n",
    "    def training_step(self,batch,batch_idx):\n",
    "        X = batch[0]\n",
    "        y = batch[1]\n",
    "        y = y.view((y.shape[0],1))\n",
    "        loss, outputs = self(x = X,labels = y)\n",
    "        mse_train = self.MSE(outputs, y)\n",
    "        \n",
    "        self.log(\"mse_train\",mse_train,prog_bar = True, logger = True, on_step=True, on_epoch=True)\n",
    "        self.log(\"train_loss\",loss,prog_bar = True, logger = True, on_step=True, on_epoch=True)\n",
    "        \n",
    "        return {\"loss\": loss}\n",
    "    \n",
    "    def validation_step(self,batch,batch_idx):\n",
    "        X = batch[0]\n",
    "        y = batch[1]\n",
    "        y = y.view((y.shape[0],1))\n",
    "        i_d = batch[2]\n",
    "        loss, outputs = self(x = X,labels = y)\n",
    "        outputs, _ = groupby_mean(outputs, i_d)\n",
    "        y, y_index = groupby_mean(y.view((y.shape[0],1)), i_d)\n",
    "        y = y.type(torch.DoubleTensor).to(device)\n",
    "        #y = y.type(torch.LongTensor).to(device)\n",
    "        loss = self.criterion(outputs,y)\n",
    "        mse_val = self.MSE(outputs, y)\n",
    "        \n",
    "        self.log(\"mse_val\",mse_val,prog_bar = True, logger = True, on_step=True, on_epoch=True)\n",
    "        self.log(\"val_loss\",loss,prog_bar = True, logger = True, on_step=True, on_epoch=True)\n",
    "        \n",
    "        return {\"loss\": loss}\n",
    "    \n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.AdamW(self.parameters(), lr =1.e-3, weight_decay=1e-3)\n",
    "        \n",
    "        lr_scheduler = {\n",
    "        'scheduler': torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=10),\n",
    "        'name': 'SDG_lr',\n",
    "        'monitor': 'val_loss_epoch'}\n",
    "\n",
    "        return [optimizer]# , [lr_scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483a5280",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the model       \n",
    "model = Speech_Predictor(model_size = model_size_)\n",
    "model.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962a2253",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checkpoint and loger definition\n",
    "checkpoint_callback = ModelCheckpoint(dirpath=checkpoint_directory,filename='ResNet_best-checkpoint-{epoch:02d}-{val_loss:.2f}_control_AT_bars_speech_nr2_grads_v4',save_top_k=3, verbose =True , monitor = 'val_loss_epoch',mode ='min')\n",
    "logger = TensorBoardLogger(parent_directory + 'lightning_logs', name = 'Speech_Resnet_bars_speech_grads_fresh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c625ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "if training_on is True:\n",
    "    #Defining the trainer object\n",
    "    trainer = pl.Trainer(logger = logger, callbacks = [checkpoint_callback], max_epochs = epochs, gpus = 0)\n",
    "    trainer.fit(model, data_module)\n",
    "\n",
    "    print('Training finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef0d356",
   "metadata": {},
   "outputs": [],
   "source": [
    "ResNet_best-checkpoint-epoch=69-val_loss=0.01_control_AT_bars_speech_nr2_grads_v0.ckpt\n",
    "ResNet_best-checkpoint-epoch=38-val_loss=0.01_control_AT_bars_speech_nr2_grads_v1.ckpt\n",
    "ResNet_best-checkpoint-epoch=55-val_loss=0.01_control_AT_bars_speech_nr2_grads_v2.ckpt\n",
    "ResNet_best-checkpoint-epoch=27-val_loss=0.01_control_AT_bars_speech_nr2_grads_v3.ckpt\n",
    "ResNet_best-checkpoint-epoch=46-val_loss=0.01_control_AT_bars_speech_nr2_grads_v4.ckpt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5fa625",
   "metadata": {},
   "source": [
    "# Model Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2c619f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Models\n",
    "checkpoint_loc_v0 = checkpoint_directory + 'Small_cnn_best-checkpoint-epoch=41-val_loss=0.02_control_AT_bars_speech_nr_v0.ckpt'\n",
    "checkpoint_loc_v1 = checkpoint_directory + 'Small_cnn_best-checkpoint-epoch=34-val_loss=0.01_control_AT_bars_speech_nr_v1.ckpt'\n",
    "checkpoint_loc_v2 = checkpoint_directory + 'Small_cnn_best-checkpoint-epoch=43-val_loss=0.01_control_AT_bars_speech_nr_v2.ckpt'\n",
    "checkpoint_loc_v3 = checkpoint_directory + 'Small_cnn_best-checkpoint-epoch=23-val_loss=0.02_control_AT_bars_speech_nr_v3.ckpt'\n",
    "checkpoint_loc_v4 = checkpoint_directory + 'Small_cnn_best-checkpoint-epoch=35-val_loss=0.02_control_AT_bars_speech_nr_v4.ckpt'\n",
    "\n",
    "\n",
    "trained_model_v0 = Speech_Predictor.load_from_checkpoint(checkpoint_loc_v0,model_size = model_size_)\n",
    "trained_model_v1 = Speech_Predictor.load_from_checkpoint(checkpoint_loc_v1,model_size = model_size_)\n",
    "trained_model_v2 = Speech_Predictor.load_from_checkpoint(checkpoint_loc_v2,model_size = model_size_)\n",
    "trained_model_v3 = Speech_Predictor.load_from_checkpoint(checkpoint_loc_v3,model_size = model_size_)\n",
    "trained_model_v4 = Speech_Predictor.load_from_checkpoint(checkpoint_loc_v4,model_size = model_size_)\n",
    "\n",
    "\n",
    "trained_model_v0.freeze()\n",
    "trained_model_v0.double()\n",
    "trained_model_v1.freeze()\n",
    "trained_model_v1.double()\n",
    "trained_model_v2.freeze()\n",
    "trained_model_v2.double()\n",
    "trained_model_v3.freeze()\n",
    "trained_model_v3.double()\n",
    "trained_model_v4.freeze()\n",
    "trained_model_v4.double()\n",
    "\n",
    "models = [trained_model_v0, trained_model_v1, trained_model_v2, trained_model_v3, trained_model_v4]\n",
    "\n",
    "\n",
    "#Demographics files\n",
    "\n",
    "val_demo_v0 = pd.read_csv(root_dir + 'val_demo_Mel_Spec_small_cnn_nr_v0.csv', names=[\"No\",\"P_ID\", \"Sex\", \"Bars\",\"Age\",\"Bars_Speech\",\"Date\"])\n",
    "val_demo_v1 = pd.read_csv(root_dir + 'val_demo_Mel_Spec_small_cnn_nr_v1.csv', names=[\"No\",\"P_ID\", \"Sex\", \"Bars\",\"Age\", \"Bars_Speech\",\"Date\"])\n",
    "val_demo_v2 = pd.read_csv(root_dir + 'val_demo_Mel_Spec_small_cnn_nr_v2.csv', names=[\"No\",\"P_ID\", \"Sex\", \"Bars\",\"Age\", \"Bars_Speech\",\"Date\"])\n",
    "val_demo_v3 = pd.read_csv(root_dir + 'val_demo_Mel_Spec_small_cnn_nr_v3.csv', names=[\"No\",\"P_ID\", \"Sex\", \"Bars\",\"Age\", \"Bars_Speech\",\"Date\"])\n",
    "val_demo_v4 = pd.read_csv(root_dir + 'val_demo_Mel_Spec_small_cnn_nr_v4.csv', names=[\"No\",\"P_ID\", \"Sex\", \"Bars\",\"Age\", \"Bars_Speech\",\"Date\"])\n",
    "val_demo_ = [val_demo_v0, val_demo_v1, val_demo_v2, val_demo_v3, val_demo_v4]\n",
    "\n",
    "#All validation data sets \n",
    "\n",
    "val_csv_file_v0 = root_dir + 'val_dataset_control_AT_Mel_Spec_2022_noise_red_v0.csv'\n",
    "val_csv_file_v1 = root_dir + 'val_dataset_control_AT_Mel_Spec_2022_noise_red_v1.csv'\n",
    "val_csv_file_v2 = root_dir + 'val_dataset_control_AT_Mel_Spec_2022_noise_red_v2.csv'\n",
    "val_csv_file_v3 = root_dir + 'val_dataset_control_AT_Mel_Spec_2022_noise_red_v3.csv'\n",
    "val_csv_file_v4 = root_dir + 'val_dataset_control_AT_Mel_Spec_2022_noise_red_v4.csv'\n",
    "\n",
    "\n",
    "test_dataset_v0 = SpeechDataset(val_csv_file_v0, root_dir + 'val_demo_Mel_Spec_small_cnn_nr_v0.csv', root_dir,plain)\n",
    "test_dataset_v1 = SpeechDataset(val_csv_file_v1, root_dir + 'val_demo_Mel_Spec_small_cnn_nr_v1.csv', root_dir,plain)\n",
    "test_dataset_v2 = SpeechDataset(val_csv_file_v2, root_dir + 'val_demo_Mel_Spec_small_cnn_nr_v2.csv', root_dir,plain)\n",
    "test_dataset_v3 = SpeechDataset(val_csv_file_v3, root_dir + 'val_demo_Mel_Spec_small_cnn_nr_v3.csv', root_dir,plain)\n",
    "test_dataset_v4 = SpeechDataset(val_csv_file_v4, root_dir + 'val_demo_Mel_Spec_small_cnn_nr_v4.csv', root_dir,plain)\n",
    "\n",
    "all_data = [test_dataset_v0, test_dataset_v1, test_dataset_v2, test_dataset_v3, test_dataset_v4]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6d9033",
   "metadata": {},
   "source": [
    "#Models\n",
    "checkpoint_loc_v0 = checkpoint_directory + 'Small_cnn_best-checkpoint-epoch=99-val_loss=0.44_control_AT_bars_speech_v0.ckpt'\n",
    "checkpoint_loc_v1 = checkpoint_directory + 'Small_cnn_best-checkpoint-epoch=97-val_loss=0.46_control_AT_bars_speech_v1.ckpt'\n",
    "checkpoint_loc_v2 = checkpoint_directory + 'Small_cnn_best-checkpoint-epoch=84-val_loss=0.43_control_AT_bars_speech_v2.ckpt'\n",
    "checkpoint_loc_v3 = checkpoint_directory + 'Small_cnn_best-checkpoint-epoch=91-val_loss=0.64_control_AT_bars_speech_v3.ckpt'\n",
    "checkpoint_loc_v4 = checkpoint_directory + 'Small_cnn_best-checkpoint-epoch=51-val_loss=0.24_control_AT_bars_speech_v4.ckpt'\n",
    "\n",
    "\n",
    "trained_model_v0 = Speech_Predictor.load_from_checkpoint(checkpoint_loc_v0, model_size = model_size_)\n",
    "trained_model_v1 = Speech_Predictor.load_from_checkpoint(checkpoint_loc_v1, model_size = model_size_)\n",
    "trained_model_v2 = Speech_Predictor.load_from_checkpoint(checkpoint_loc_v2, model_size = model_size_)\n",
    "trained_model_v3 = Speech_Predictor.load_from_checkpoint(checkpoint_loc_v3, model_size = model_size_)\n",
    "trained_model_v4 = Speech_Predictor.load_from_checkpoint(checkpoint_loc_v4, model_size = model_size_)\n",
    "\n",
    "trained_model_v0.freeze()\n",
    "trained_model_v0.double()\n",
    "trained_model_v1.freeze()\n",
    "trained_model_v1.double()\n",
    "trained_model_v2.freeze()\n",
    "trained_model_v2.double()\n",
    "trained_model_v3.freeze()\n",
    "trained_model_v3.double()\n",
    "trained_model_v4.freeze()\n",
    "trained_model_v4.double()\n",
    "\n",
    "models = [trained_model_v0, trained_model_v1, trained_model_v2, trained_model_v3, trained_model_v4]\n",
    "\n",
    "#Demographics files\n",
    "\n",
    "val_demo_v0 = pd.read_csv(root_dir + 'val_demo_Mel_Spec_small_cnn_v0.csv', names=[\"No\",\"P_ID\", \"Sex\", \"Bars\",\"Age\",\"Bars_Speech\",\"Date\"])\n",
    "val_demo_v1 = pd.read_csv(root_dir + 'val_demo_Mel_Spec_small_cnn_v1.csv', names=[\"No\",\"P_ID\", \"Sex\", \"Bars\",\"Age\", \"Bars_Speech\",\"Date\"])\n",
    "val_demo_v2 = pd.read_csv(root_dir + 'val_demo_Mel_Spec_small_cnn_v2.csv', names=[\"No\",\"P_ID\", \"Sex\", \"Bars\",\"Age\", \"Bars_Speech\",\"Date\"])\n",
    "val_demo_v3 = pd.read_csv(root_dir + 'val_demo_Mel_Spec_small_cnn_v3.csv', names=[\"No\",\"P_ID\", \"Sex\", \"Bars\",\"Age\", \"Bars_Speech\",\"Date\"])\n",
    "val_demo_v4 = pd.read_csv(root_dir + 'val_demo_Mel_Spec_small_cnn_v4.csv', names=[\"No\",\"P_ID\", \"Sex\", \"Bars\",\"Age\", \"Bars_Speech\",\"Date\"])\n",
    "\n",
    "val_demo_ = [val_demo_v0, val_demo_v1, val_demo_v2, val_demo_v3, val_demo_v4]\n",
    "\n",
    "#All validation data sets \n",
    "\n",
    "val_csv_file_v0 = root_dir + 'val_dataset_control_AT_Mel_Spec_2022_norm_win_v0.csv'\n",
    "val_csv_file_v1 = root_dir + 'val_dataset_control_AT_Mel_Spec_2022_norm_win_v1.csv'\n",
    "val_csv_file_v2 = root_dir + 'val_dataset_control_AT_Mel_Spec_2022_norm_win_v2.csv'\n",
    "val_csv_file_v3 = root_dir + 'val_dataset_control_AT_Mel_Spec_2022_norm_win_v3.csv'\n",
    "val_csv_file_v4 = root_dir + 'val_dataset_control_AT_Mel_Spec_2022_norm_win_v4.csv'\n",
    "\n",
    "test_dataset_v0 = SpeechDataset(val_csv_file_v0, root_dir + 'val_demo_Mel_Spec_small_cnn_v0.csv', root_dir,plain)\n",
    "test_dataset_v1 = SpeechDataset(val_csv_file_v1, root_dir + 'val_demo_Mel_Spec_small_cnn_v1.csv', root_dir,plain)\n",
    "test_dataset_v2 = SpeechDataset(val_csv_file_v2, root_dir + 'val_demo_Mel_Spec_small_cnn_v2.csv', root_dir,plain)\n",
    "test_dataset_v3 = SpeechDataset(val_csv_file_v3, root_dir + 'val_demo_Mel_Spec_small_cnn_v3.csv', root_dir,plain)\n",
    "test_dataset_v4 = SpeechDataset(val_csv_file_v4, root_dir + 'val_demo_Mel_Spec_small_cnn_v4.csv', root_dir,plain)\n",
    "\n",
    "all_data = [test_dataset_v0, test_dataset_v1, test_dataset_v2, test_dataset_v3, test_dataset_v4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494fac05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the output of the models\n",
    "val_demo__ = []\n",
    "for i in range(5):\n",
    "    test_dataset = all_data[i]\n",
    "    trained_model = models[i]\n",
    "    val_demo = val_demo_[i]\n",
    "    bars_pred = []\n",
    "    y_label_list =[]\n",
    "    bars_obsr_list =[]\n",
    "    date_list = []\n",
    "    for sample in test_dataset:\n",
    "        X_s, bars,date_, y_label = sample\n",
    "        \n",
    "        if X_s.shape[1]< 50:\n",
    "            bars_pred.append(np.nan)\n",
    "            bars_obsr_list.append(np.nan)\n",
    "            continue\n",
    "        \n",
    "        input_ = X_s.double().unsqueeze(0)\n",
    "        output = trained_model(input_)\n",
    "        \n",
    "        val_demo.loc[(val_demo.Date == date_[0].detach().cpu().numpy()),'Label'] = y_label[0].detach().cpu().numpy()\n",
    "        bars_pred.append(4*output[0][0].detach().cpu().numpy())\n",
    "        bars_obsr_list.append(4*bars[0].detach().cpu().numpy())\n",
    "        #y_label_list.append(y_label[0].detach().cpu().numpy())\n",
    "        #date_list.append(date_[0].detach().cpu().numpy())\n",
    "    \n",
    "    val_demo = val_demo[val_demo['Label'] == 1.]\n",
    "    val_demo = val_demo[val_demo['Bars'].notna()]\n",
    "    val_demo = val_demo[val_demo['Bars']>= 0.]\n",
    "    val_demo.loc[val_demo['Bars'].notna(), \"BARS_pred\"] = bars_pred\n",
    "    val_demo.loc[val_demo['Bars'].notna(), \"BARS_obsr\"] = bars_obsr_list\n",
    "    val_demo__.append(val_demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5443b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#val_demo__ = [val_demo_[0], val_demo_[1], val_demo_[2], val_demo_[3], val_demo_[4],\n",
    "#              val_demo_[5], val_demo_[6], val_demo_[7], val_demo_[8], val_demo_[9]]\n",
    "val_demo_all = pd.concat(val_demo__, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cd5b9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bc8583",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515f02c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "val_demo_bars = val_demo_all[['P_ID','Sex','Label', 'Age','BARS_obsr', 'BARS_pred','Date']]\n",
    "val_demo_bars = val_demo_bars[val_demo_bars['BARS_obsr'].notna()]\n",
    "val_demo_bars = val_demo_bars[val_demo_bars['BARS_obsr'] >= 0]\n",
    "val_demo_bars_male = val_demo_bars[val_demo_bars['Sex'] == \"M\"]\n",
    "val_demo_bars_female = val_demo_bars[val_demo_bars['Sex'] == \"F\"]\n",
    "val_demo_bars_male[\"ID_ranked\"] = val_demo_bars_male[\"P_ID\"]#.rank()-1\n",
    "val_demo_bars_female[\"ID_ranked\"] = val_demo_bars_female[\"P_ID\"]#.rank()-1\n",
    "val_demo_bars = val_demo_bars[['P_ID','Label', 'Age','BARS_obsr', 'BARS_pred', 'Date']].astype('float64')\n",
    "val_demo_bars = val_demo_bars.groupby(['Date'], as_index = False).median()\n",
    "\n",
    "\n",
    "val_demo_bars_male = val_demo_bars_male[['ID_ranked','Label', 'Age','BARS_obsr', 'BARS_pred','Date']]\n",
    "val_demo_bars_male = val_demo_bars_male.astype('float64')\n",
    "\n",
    "val_demo_bars_female = val_demo_bars_female[['ID_ranked','Label', 'Age','BARS_obsr', 'BARS_pred','Date']]\n",
    "val_demo_bars_female = val_demo_bars_female.astype('float64')\n",
    "\n",
    "\n",
    "val_demo_bars_male_lower68 = val_demo_bars_male.groupby(['Date'], as_index = False).quantile(0.159)\n",
    "val_demo_bars_female_lower68 = val_demo_bars_female.groupby(['Date'], as_index = False).quantile(0.159)\n",
    "\n",
    "val_demo_bars_male_upper68 = val_demo_bars_male.groupby(['Date'], as_index = False).quantile(0.841)\n",
    "val_demo_bars_female_upper68 = val_demo_bars_female.groupby(['Date'], as_index = False).quantile(0.841)\n",
    "\n",
    "val_demo_bars_male = val_demo_bars_male.groupby(['Date'], as_index = False).mean()\n",
    "val_demo_bars_female = val_demo_bars_female.groupby(['Date'], as_index = False).mean()\n",
    "\n",
    "cmap = plt.get_cmap('gray')\n",
    "new_cmap = truncate_colormap(cmap, 0.2, 1)\n",
    "\n",
    "val_demo_bars_ = pd.concat([val_demo_bars_male, val_demo_bars_female], ignore_index=True)\n",
    "#sns.kdeplot(x=val_demo_bars_['BARS_obsr'], y=val_demo_bars_['BARS_pred'], cmap=new_cmap, shade=True, bw_adjust=.65, clip=([-0.5,30],[-0.5, 30.0]))\n",
    "\n",
    "ax.scatter(val_demo_bars_male['BARS_obsr'], val_demo_bars_male['BARS_pred'], c = 'red', marker = 'o', s = 2*val_demo_bars_male['Age'])\n",
    "ax.scatter(val_demo_bars_female['BARS_obsr'], val_demo_bars_female['BARS_pred'], c = 'red', marker = 'x', s = 2* val_demo_bars_female['Age'])\n",
    "ax.plot([0, 4], [0, 4],color = 'k',linewidth = 5,linestyle ='-.')\n",
    "\n",
    "ax.fill_between([0,4], [-0.41, 4 -0.41], [0.41, 4 + 0.41], color='k', alpha=.1)\n",
    "\n",
    "z, V = np.polyfit(val_demo_bars['BARS_obsr'], val_demo_bars['BARS_pred'], 1, cov=True)\n",
    "p = np.poly1d(z)\n",
    "slope_err = np.sqrt(V[0][0])\n",
    "inter_err = np.sqrt(V[1][1])\n",
    "plt.plot(range(5),p(range(5)),\"k\",linewidth = 3)\n",
    "\n",
    "#ax.fill_between([0,4], [p(0)-inter_err , p(4) - 4 * slope_err - inter_err], [p(0)+inter_err , p(4) + 4 * slope_err + inter_err], color='k', alpha=.1)\n",
    "\n",
    "\n",
    "\n",
    "ax.minorticks_on()\n",
    "ax.tick_params('both', length=10, width=2, which='major',direction=\"in\")\n",
    "ax.tick_params('both', length=5, width=1, which='minor',direction=\"in\")\n",
    "ax.tick_params(axis='x', labelsize=35)\n",
    "ax.tick_params(axis='y', labelsize=35)\n",
    "ax.set_aspect(1)\n",
    "plt.xlim([-0.15, 4])\n",
    "plt.ylim([-0.3, 4])\n",
    "plt.xlabel(r'$BARS^{clin}_{speech}$', fontsize=40)\n",
    "plt.ylabel(r'$BARS^{pred}_{speech}$', fontsize=40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c37c31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e661288c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(val_demo_bars['BARS_obsr'], val_demo_bars['BARS_pred'],squared = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53da7a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(val_demo_bars['BARS_obsr'], val_demo_bars['BARS_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0ec89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(val_demo_bars['BARS_obsr'], val_demo_bars['BARS_pred'], multioutput='variance_weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e78cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "val_demo_bars = val_demo_all[['P_ID','Sex','Label', 'Age','BARS_obsr', 'BARS_pred','Date']]\n",
    "val_demo_bars = val_demo_bars[val_demo_bars['BARS_obsr'].notna()]\n",
    "val_demo_bars = val_demo_bars[val_demo_bars['BARS_obsr'] >= 0]\n",
    "val_demo_bars = val_demo_bars[val_demo_bars['Label'] == 1]\n",
    "val_demo_bars_male = val_demo_bars[val_demo_bars['Sex'] == \"M\"]\n",
    "val_demo_bars_female = val_demo_bars[val_demo_bars['Sex'] == \"F\"]\n",
    "val_demo_bars_male[\"ID_ranked\"] = val_demo_bars_male[\"P_ID\"]#.rank()-1\n",
    "val_demo_bars_female[\"ID_ranked\"] = val_demo_bars_female[\"P_ID\"]#.rank()-1\n",
    "val_demo_bars = val_demo_bars[['P_ID','Label', 'Age','BARS_obsr', 'BARS_pred', 'Date']].astype('float64')\n",
    "val_demo_bars = val_demo_bars.groupby(['Date'], as_index = False).median()\n",
    "\n",
    "\n",
    "val_demo_bars_male = val_demo_bars_male[['ID_ranked','Label', 'Age','BARS_obsr', 'BARS_pred','Date']]\n",
    "val_demo_bars_male = val_demo_bars_male.astype('float64')\n",
    "\n",
    "val_demo_bars_female = val_demo_bars_female[['ID_ranked','Label', 'Age','BARS_obsr', 'BARS_pred','Date']]\n",
    "val_demo_bars_female = val_demo_bars_female.astype('float64')\n",
    "\n",
    "\n",
    "val_demo_bars_male = val_demo_bars_male.groupby(['Date'], as_index = False).median()\n",
    "val_demo_bars_female = val_demo_bars_female.groupby(['Date'], as_index = False).median()\n",
    "\n",
    "\n",
    "male_month_diff_1 = []\n",
    "male_month_diff_2 = []\n",
    "male_month_diff_3 = []\n",
    "male_month_diff_4 = []\n",
    "male_bars_diff_1 = []\n",
    "male_bars_diff_2 = []\n",
    "male_bars_diff_3 = []\n",
    "male_bars_diff_4 = []\n",
    "male_init_bars = []\n",
    "female_month_diff_1 = []\n",
    "female_month_diff_2 = []\n",
    "female_month_diff_3 = []\n",
    "female_month_diff_4 = []\n",
    "female_bars_diff_1 = []\n",
    "female_bars_diff_2 = []\n",
    "female_bars_diff_3 = []\n",
    "female_bars_diff_4 = []\n",
    "female_init_bars = []\n",
    "\n",
    "#print(val_demo_bars_male['Date'].astype(str).str[5:9].astype(float)*12. + val_demo_bars_male['Date'].astype(str).str[9:11].astype(float))\n",
    "for vv in val_demo_bars_male['ID_ranked'].unique():\n",
    "    if val_demo_bars_male['ID_ranked'].value_counts().loc[vv] > 1:\n",
    "        val_demo_bars_male_lines = val_demo_bars_male[val_demo_bars_male['ID_ranked'] == vv]\n",
    "        val_demo_bars_male_lines = val_demo_bars_male_lines.sort_values(by=['Date'])\n",
    "        val_demo_bars_male_lines['Months'] = val_demo_bars_male_lines['Date'].astype(str).str[5:9].astype(float)*12. + val_demo_bars_male_lines['Date'].astype(str).str[9:11].astype(float)\n",
    "        month_diff = val_demo_bars_male_lines['Months'].iloc[-1]- val_demo_bars_male_lines['Months'].iloc[0]\n",
    "        if month_diff > 1:\n",
    "            male_init_bars.append(val_demo_bars_male_lines['BARS_obsr'].iloc[0])\n",
    "            Bars_pred_diff = val_demo_bars_male_lines['BARS_pred'].iloc[-1]- val_demo_bars_male_lines['BARS_pred'].iloc[0]\n",
    "            Bars_obs_diff = val_demo_bars_male_lines['BARS_obsr'].iloc[-1]- val_demo_bars_male_lines['BARS_obsr'].iloc[0]\n",
    "            if Bars_obs_diff == 0.:\n",
    "                male_bars_diff_1.append(Bars_pred_diff)\n",
    "                male_month_diff_1.append(month_diff)\n",
    "            elif ((Bars_obs_diff > 0.0) and (Bars_obs_diff < 0.75)):\n",
    "                male_bars_diff_2.append(Bars_pred_diff)\n",
    "                male_month_diff_2.append(month_diff)\n",
    "            else:\n",
    "                male_bars_diff_3.append(Bars_pred_diff)\n",
    "                male_month_diff_3.append(month_diff)\n",
    "            if Bars_pred_diff < 0:\n",
    "                print(vv)\n",
    "            \n",
    "for vv in val_demo_bars_female['ID_ranked'].unique():\n",
    "    if val_demo_bars_female['ID_ranked'].value_counts().loc[vv] > 1:\n",
    "        val_demo_bars_female_lines = val_demo_bars_female[val_demo_bars_female['ID_ranked'] == vv]\n",
    "        val_demo_bars_female_lines = val_demo_bars_female_lines.sort_values(by=['Date'])\n",
    "        val_demo_bars_female_lines['Months'] = val_demo_bars_female_lines['Date'].astype(str).str[5:9].astype(float)*12. + val_demo_bars_female_lines['Date'].astype(str).str[9:11].astype(float)\n",
    "        month_diff = val_demo_bars_female_lines['Months'].iloc[-1]- val_demo_bars_female_lines['Months'].iloc[0]\n",
    "        if month_diff > 1:\n",
    "            female_init_bars.append(val_demo_bars_female_lines['BARS_obsr'].iloc[0])\n",
    "            Bars_pred_diff = val_demo_bars_female_lines['BARS_pred'].iloc[-1]- val_demo_bars_female_lines['BARS_pred'].iloc[0]\n",
    "            Bars_obs_diff = val_demo_bars_female_lines['BARS_obsr'].iloc[-1]- val_demo_bars_female_lines['BARS_obsr'].iloc[0]\n",
    "            if Bars_obs_diff == 0:\n",
    "                female_bars_diff_1.append(Bars_pred_diff)\n",
    "                female_month_diff_1.append(month_diff)\n",
    "            elif ((Bars_obs_diff > 0) and (Bars_obs_diff < 0.50)):\n",
    "                female_bars_diff_2.append(Bars_pred_diff)\n",
    "                female_month_diff_2.append(month_diff)\n",
    "            else:\n",
    "                female_bars_diff_3.append(Bars_pred_diff)\n",
    "                female_month_diff_3.append(month_diff)\n",
    "            if Bars_pred_diff < 0:\n",
    "                print(vv)\n",
    "                \n",
    "ax.scatter(male_month_diff_1, male_bars_diff_1, c = 'red', marker = 'o',s = 90)#10*np.array(male_init_bars))\n",
    "ax.scatter(male_month_diff_2, male_bars_diff_2, c = 'red', marker = 'o',s = 90)#10*np.array(male_init_bars))\n",
    "ax.scatter(male_month_diff_3, male_bars_diff_3, c = 'red', marker = 'o',s = 90)#10*np.array(male_init_bars))\n",
    "#ax.scatter(male_month_diff_4, male_bars_diff_4, c = 'orange', marker = 'o',s = 70)#10*np.array(male_init_bars))\n",
    "\n",
    "ax.scatter(female_month_diff_1, female_bars_diff_1, c = 'red', marker = 'o',s = 90)#10*np.array(male_init_bars))\n",
    "ax.scatter(female_month_diff_2, female_bars_diff_2, c = 'red', marker = 'o',s = 90)#10*np.array(male_init_bars))\n",
    "ax.scatter(female_month_diff_3, female_bars_diff_3, c = 'red', marker = 'o',s = 90)#10*np.array(male_init_bars))\n",
    "#ax.scatter(female_month_diff_4, female_bars_diff_4, c = 'orange', marker = 'x',s = 70)#10*np.array(male_init_bars))\n",
    "\n",
    "print(np.mean(male_bars_diff_1 + male_bars_diff_2 + male_bars_diff_3 + female_bars_diff_1 + female_bars_diff_2 + female_bars_diff_3 ), np.std(male_bars_diff_1 + male_bars_diff_2 + male_bars_diff_3 + female_bars_diff_1 + female_bars_diff_2 + female_bars_diff_3 ))\n",
    "\n",
    "ax.scatter([], [], c = 'red', marker = 'o',s = 90, label=r'$\\rm{\\Delta BARS^{clin}_{speech}} = 0$')#10*np.array(male_init_bars))\n",
    "ax.scatter([], [], c = 'red', marker = 'o',s = 90, label=r'$0 < \\rm{\\Delta BARS^{clin}_{speech}} < 0.75$')#10*np.array(male_init_bars))\n",
    "ax.scatter([], [], c = 'red', marker = 'o',s = 90, label=r'$\\rm{\\Delta BARS^{clin}_{speech}}$ > 0.75')#10*np.array(male_init_bars))\n",
    "#plt.legend(fontsize=25,loc = 'lower right')\n",
    "ax.minorticks_on()\n",
    "ax.tick_params('both', length=10, width=2, which='major',direction=\"in\")\n",
    "ax.tick_params('both', length=5, width=1, which='minor',direction=\"in\")\n",
    "\n",
    "plt.axhline(y=0., color='k', linestyle='--')\n",
    "#plt.axhline(y=0.75, color='k', linestyle='--')\n",
    "ax.tick_params(axis='x', labelsize=35)\n",
    "ax.tick_params(axis='y', labelsize=35)\n",
    "#ax.set_aspect(12.5)\n",
    "plt.xlim([-0.2, 45])\n",
    "plt.ylim([-1.1, 1.1])\n",
    "plt.xlabel(r'$\\rm{Months}$', fontsize=40)\n",
    "plt.ylabel(r'$\\rm{\\Delta BARS^{pred}_{speech}}$', fontsize=40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11953649",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_diff =  male_month_diff_1 + male_month_diff_2 + male_month_diff_3 + female_month_diff_1 + female_month_diff_2 + female_month_diff_3 \n",
    "bars_diff = male_bars_diff_1 + male_bars_diff_2 + male_bars_diff_3  + female_bars_diff_1 + female_bars_diff_2 + female_bars_diff_3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34899b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.spearmanr( month_diff, bars_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63af5b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_1samp(bars_diff, 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df65bbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70e8ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_demo_bars = val_demo_all[['P_ID','Sex','Label', 'Age','BARS_obsr', 'BARS_pred','Date']]\n",
    "val_demo_bars = val_demo_bars[val_demo_bars['BARS_obsr'].notna()]\n",
    "val_demo_bars = val_demo_bars[val_demo_bars['BARS_obsr'] >= 0]\n",
    "val_demo_bars_male = val_demo_bars[val_demo_bars['Sex'] == \"M\"]\n",
    "val_demo_bars_female = val_demo_bars[val_demo_bars['Sex'] == \"F\"]\n",
    "val_demo_bars_male[\"ID_ranked\"] = val_demo_bars_male[\"P_ID\"]#.rank()-1\n",
    "val_demo_bars_female[\"ID_ranked\"] = val_demo_bars_female[\"P_ID\"]#.rank()-1\n",
    "val_demo_bars = val_demo_bars[['P_ID','Label', 'Age','BARS_obsr', 'BARS_pred', 'Date']].astype('float64')\n",
    "val_demo_bars = val_demo_bars.groupby(['Date'], as_index = False).median()\n",
    "\n",
    "\n",
    "val_demo_bars_male = val_demo_bars_male[['ID_ranked','Label', 'Age','BARS_obsr', 'BARS_pred','Date']]\n",
    "val_demo_bars_male = val_demo_bars_male.astype('float64')\n",
    "\n",
    "val_demo_bars_female = val_demo_bars_female[['ID_ranked','Label', 'Age','BARS_obsr', 'BARS_pred','Date']]\n",
    "val_demo_bars_female = val_demo_bars_female.astype('float64')\n",
    "\n",
    "\n",
    "val_demo_bars_male = val_demo_bars_male.groupby(['Date'], as_index = False).median()\n",
    "val_demo_bars_female = val_demo_bars_female.groupby(['Date'], as_index = False).median()\n",
    "\n",
    "val_demo_bars_male['MAE'] = np.abs(val_demo_bars_male['BARS_obsr'] - val_demo_bars_male['BARS_pred'])\n",
    "val_demo_bars_female['MAE'] = np.abs(val_demo_bars_female['BARS_obsr'] - val_demo_bars_female['BARS_pred'])\n",
    "\n",
    "val_demo_bars_male_np_control = val_demo_bars_male[(val_demo_bars_male['Label'] == 0) ]['MAE'].to_numpy()\n",
    "val_demo_bars_female_np_control = val_demo_bars_female[(val_demo_bars_female['Label'] == 0)]['MAE'].to_numpy()\n",
    "\n",
    "val_demo_bars_male_np_ataxia = val_demo_bars_male[(val_demo_bars_male['Label'] == 1) ]['MAE'].to_numpy()\n",
    "val_demo_bars_female_np_ataxia = val_demo_bars_female[(val_demo_bars_female['Label'] == 1)]['MAE'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bfc767",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_ind(a=val_demo_bars_male_np_control, b=val_demo_bars_female_np_control, equal_var=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d330d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_ind(a=val_demo_bars_male_np_ataxia, b=val_demo_bars_female_np_ataxia, equal_var=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cb7269",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_demo_bars = val_demo_all[['P_ID','Sex','Label', 'Age','BARS_obsr', 'BARS_pred','Date']]\n",
    "val_demo_bars = val_demo_bars[val_demo_bars['BARS_obsr'].notna()]\n",
    "val_demo_bars = val_demo_bars[val_demo_bars['BARS_obsr'] >= 0]\n",
    "val_demo_bars = val_demo_bars[val_demo_bars['Label'] == 1]\n",
    "val_demo_bars['MAE'] = np.abs(val_demo_bars['BARS_obsr'] - val_demo_bars['BARS_pred'])\n",
    "val_demo_bars.loc[(val_demo_bars.Label == 0),'Bars']= 0.\n",
    "val_demo_bars.loc[(val_demo_bars.Sex == 'M'),'Sex']= 0\n",
    "val_demo_bars.loc[(val_demo_bars.Sex == 'F'),'Sex']= 1\n",
    "val_demo_bars[\"ID_ranked\"] = val_demo_bars[\"P_ID\"].rank()-1\n",
    "val_demo_bars = val_demo_bars.astype('float64')\n",
    "val_demo_bars = val_demo_bars.groupby(['Date',\"Age\"], as_index = False).median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5aba46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_demo_bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784b9b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_demo_bars[['MAE','Age']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de070f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.spearmanr(val_demo_bars['Age'], val_demo_bars['MAE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f574f6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d17f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_demo_bars = val_demo_all[['P_ID','Sex','Label', 'Age','BARS_obsr', 'BARS_pred','Date']]\n",
    "val_demo_bars = val_demo_bars[val_demo_bars['BARS_obsr'].notna()]\n",
    "val_demo_bars = val_demo_bars[val_demo_bars['BARS_obsr'] >= 0]\n",
    "val_demo_bars = val_demo_bars[val_demo_bars['Label'] == 1]\n",
    "val_demo_bars['MAE'] = np.abs(val_demo_bars['BARS_obsr'] - val_demo_bars['BARS_pred'])\n",
    "val_demo_bars.loc[(val_demo_bars.Label == 0),'Bars']= 0.\n",
    "val_demo_bars.loc[(val_demo_bars.Sex == 'M'),'Sex']= 0\n",
    "val_demo_bars.loc[(val_demo_bars.Sex == 'F'),'Sex']= 1\n",
    "val_demo_bars[\"ID_ranked\"] = val_demo_bars[\"P_ID\"].rank()-1\n",
    "val_demo_bars = val_demo_bars.astype('float64')\n",
    "val_demo_bars = val_demo_bars.groupby(['Date',\"Age\"], as_index = False).median()\n",
    "\n",
    "val_demo_bars_0 = val_demo_bars[val_demo_bars['BARS_obsr'] == 0]\n",
    "val_demo_bars_05 = val_demo_bars[val_demo_bars['BARS_obsr'] == 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c9013c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_ind(a=val_demo_bars_0['BARS_pred'], b=val_demo_bars_05['BARS_pred'], equal_var=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d78e871",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(val_demo_bars_0['BARS_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1c6fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(val_demo_bars_05['BARS_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96cd030",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40a56ddc",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7065574",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels = trained_model_v3.model.C1.weight.data\n",
    "for i in range(kernels.shape[0]):\n",
    "    fig = plt.figure()\n",
    "    ax1 = fig.add_subplot(1, 1, 1)\n",
    "    ax1.imshow((kernels.numpy()[i][0] - np.mean(kernels.numpy()[i][0]))/np.std(kernels.numpy()[i][0]))\n",
    "    ax1.axis('off')\n",
    "    ax1.set_xticklabels([])\n",
    "    ax1.set_yticklabels([])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0accce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
