{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dc3ec84",
   "metadata": {},
   "source": [
    "# Speech classifier for NDs using RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd364ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basics\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import csv\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import scipy.stats as stats\n",
    "import scipy.signal as signal\n",
    "from scipy.stats import shapiro,normaltest,kstest,uniform\n",
    "import seaborn as sns\n",
    "import matplotlib.colors as colors\n",
    "sys.path.append('../../')\n",
    "\n",
    "#sklearn \n",
    "from multiprocessing import cpu_count\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix,f1_score, roc_curve,auc, roc_auc_score,ConfusionMatrixDisplay\n",
    "\n",
    "#Pytorch\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch. optim.lr_scheduler import _LRScheduler\n",
    "import torch.optim as optim\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "import torchvision.models as models\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "#Pytorch lightning\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks.model_checkpoint import ModelCheckpoint\n",
    "from pytorch_lightning.metrics.functional import accuracy\n",
    "from pytorch_lightning import Trainer\n",
    "import torchmetrics\n",
    "\n",
    "#models\n",
    "from script.models import CNN_short_fc,CNN_short_fc_wide,FC_Resnet_\n",
    "\n",
    "#utils\n",
    "from script.utils import KFoldCVDataModule, CVTrainer, PadImage_inf, ImbalancedDatasetSampler\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "#Captum\n",
    "from captum.attr import IntegratedGradients\n",
    "from captum.attr import GradientShap\n",
    "from captum.attr import Occlusion\n",
    "from captum.attr import NoiseTunnel\n",
    "from captum.attr import visualization as viz\n",
    "from matplotlib.colors import LinearSegmentedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf92f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "torch.manual_seed(42)\n",
    "pd.set_option('float_format', '{:f}'.format)\n",
    "#torch.backends.cudnn.benchmark = True\n",
    "%matplotlib inline\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "default_cmap = LinearSegmentedColormap.from_list('custom blue', \n",
    "                                                 [(0, '#ffffff'),\n",
    "                                                  (0.25, '#000000'),\n",
    "                                                  (1, '#000000')], N=256)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4fe08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_colormap(cmap, minval=0.0, maxval=1.0, n=100):\n",
    "    new_cmap = colors.LinearSegmentedColormap.from_list(\n",
    "        'trunc({n},{a:.2f},{b:.2f})'.format(n=cmap.name, a=minval, b=maxval),\n",
    "        cmap(np.linspace(minval, maxval, n)))\n",
    "    return new_cmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c427e5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter definition\n",
    "epochs = 100 # no of epochs\n",
    "model_size_ = '18'\n",
    "Batch_Size = 128 #batch size\n",
    "no_feutures = 128 #no of features per entry\n",
    "training_on = False\n",
    "root_dir = '/home/kvattis/Documents/data/'\n",
    "train_csv_file = root_dir + 'train_dataset_control_AT_Mel_Spec_2022_noise_red_v0.csv'\n",
    "val_csv_file = root_dir + 'val_dataset_control_AT_Mel_Spec_2022_noise_red_v0.csv'\n",
    "train_demo_csv_file = root_dir +'train_demo_Mel_Spec_small_cnn_nr_v0.csv'\n",
    "val_demo_csv_file = root_dir + 'val_demo_Mel_Spec_small_cnn_nr_v0.csv'\n",
    "parent_directory = '/home/kvattis/Documents/speech_analysis/'\n",
    "checkpoint_directory = parent_directory + 'checkpoints/resnet_regression_speech_10fold_fresh__wc/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026f4b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_class = [3487,8145]\n",
    "weights = [1/x for x in n_class]\n",
    "weights = [ww/np.sum(weights) for ww in weights]\n",
    "#weights = [0.75, 0.25]\n",
    "class_weights = torch.FloatTensor(weights)\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2b0119",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scale(X, range_=(0, 1)):\n",
    "    mi, ma = range_\n",
    "    X_min = -50\n",
    "    X_max = 50\n",
    "    #X_std = (X - X.min()) / (X.max() - X.min())\n",
    "    X_std = (X - X_min) / (X_max - X_min)\n",
    "    X_scaled = X_std * (ma - mi) + mi\n",
    "    return X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a072c10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augm(spec,l):\n",
    "    freq_mask_param = 25\n",
    "    time_mask_param = 10\n",
    "    \n",
    "    masking_T = T.TimeMasking(time_mask_param=time_mask_param)\n",
    "    masking_f = T.FrequencyMasking(freq_mask_param = freq_mask_param)\n",
    "\n",
    "    spec = masking_T(spec)\n",
    "    spec = masking_f(spec)\n",
    "    \n",
    "    return spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03a6621",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup_data(x, y, alpha=1.0):\n",
    "    '''Returns mixed inputs, pairs of targets, and lambda'''\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "\n",
    "    batch_size = x.size()[0]\n",
    "    \n",
    "    index = torch.randperm(batch_size)\n",
    "\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c35004",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d9424b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plain(spec,l):\n",
    "    return spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66354aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def groupby_mean(value:torch.Tensor, labels:torch.LongTensor) -> (torch.Tensor, torch.LongTensor):\n",
    "    \"\"\"Group-wise average for (sparse) grouped tensors\n",
    "\n",
    "    Args:\n",
    "        value (torch.Tensor): values to average (# samples, latent dimension)\n",
    "        labels (torch.LongTensor): labels for embedding parameters (# samples,)\n",
    "\n",
    "    Returns: \n",
    "        result (torch.Tensor): (# unique labels, latent dimension)\n",
    "        new_labels (torch.LongTensor): (# unique labels,)\n",
    "\n",
    "    Examples:\n",
    "        >>> samples = torch.Tensor([\n",
    "                             [0.15, 0.15, 0.15],    #-> group / class 1\n",
    "                             [0.2, 0.2, 0.2],    #-> group / class 3\n",
    "                             [0.4, 0.4, 0.4],    #-> group / class 3\n",
    "                             [0.0, 0.0, 0.0]     #-> group / class 0\n",
    "                      ])\n",
    "        >>> labels = torch.LongTensor([1, 5, 5, 0])\n",
    "        >>> result, new_labels = groupby_mean(samples, labels)\n",
    "\n",
    "        >>> result\n",
    "        tensor([[0.0000, 0.0000, 0.0000],\n",
    "            [0.1500, 0.1500, 0.1500],\n",
    "            [0.3000, 0.3000, 0.3000]])\n",
    "\n",
    "        >>> new_labels\n",
    "        tensor([0, 1, 5])\n",
    "    \"\"\"\n",
    "    uniques = labels.unique().tolist()\n",
    "    labels = labels.tolist()\n",
    "\n",
    "    key_val = {key: val for key, val in zip(uniques, range(len(uniques)))}\n",
    "    val_key = {val: key for key, val in zip(uniques, range(len(uniques)))}\n",
    "\n",
    "    labels = torch.LongTensor(list(map(key_val.get, labels)))\n",
    "\n",
    "    labels = labels.view(labels.size(0), 1).expand(-1, value.size(1))\n",
    "\n",
    "    unique_labels, labels_count = labels.unique(dim=0, return_counts=True)\n",
    "    result = torch.zeros_like(unique_labels.to(device), dtype=value.dtype).scatter_add_(0, labels.to(device), value.to(device))\n",
    "    result = result.to(device) / labels_count.float().unsqueeze(1).to(device)\n",
    "    new_labels = torch.LongTensor(list(map(val_key.get, unique_labels[:, 0].tolist())))\n",
    "    return result.to(device), new_labels.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32cf4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting standard filter requirements.\n",
    "order = 6\n",
    "nyq_freq = 30.0       \n",
    "cutoff_frequency = 7.5#3.667  \n",
    "\n",
    "def butterLow(cutoff, critical, order):\n",
    "    normal_cutoff = float(cutoff) / critical\n",
    "    b, a = signal.butter(order, normal_cutoff, btype='lowpass')\n",
    "    return b, a\n",
    "\n",
    "def butterFilter(data, cutoff_freq, nyq_freq, order):\n",
    "    b, a = butterLow(cutoff_freq, nyq_freq, order)\n",
    "    y = signal.filtfilt(b, a, data)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdac92d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transforms_val(spec,l):\n",
    "    transforms_resize = transforms.Resize((100, 100))\n",
    "    spec = transforms_resize(spec)\n",
    "    return spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a06533",
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_std(X, mean = -0.0005, std = 0.0454):\n",
    "    X_scaled = (X - mean)/ std\n",
    "    return X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ae8a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a pytorch Dataset               \n",
    "class SpeechDataset(Dataset):\n",
    "    def __init__(self, csv_file, demo_csv, root_dir,transform):\n",
    "            \n",
    "        self.file_names = pd.read_csv(csv_file,header = None, names=[\"No\",\"P_ID\", \"Address\",\"Label\",\"Date\"])\n",
    "        self.demo = pd.read_csv(demo_csv, names=[\"No\",\"P_ID\", \"Sex\", \"Bars\",\"Age\",\"Bars_Speech\", \"PDate\"])\n",
    "        self.file_names['Bars'] = self.demo['Bars_Speech']\n",
    "        self.file_names.loc[(self.file_names.Label == 0),'Bars']= 0.\n",
    "        #self.file_names = self.file_names[self.file_names.Label == 1] \n",
    "        self.file_names = self.file_names[self.file_names.Bars >= 0.] \n",
    "        self.file_names_bars = self.file_names[self.file_names['Bars'].notna()] \n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_names_bars)   \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        address =  os.path.join(self.root_dir,\n",
    "                                self.file_names_bars.iloc[idx, 2])\n",
    "                \n",
    "        df = pd.read_csv(address,header = None)                                                                              \n",
    "        df_ar = df.to_numpy()\n",
    "        df_ar = min_max_scale(df_ar)\n",
    "        \n",
    "        df_ar_t = np.gradient(df_ar, axis = 0)\n",
    "        #df_ar_t = butterFilter(df_ar_t, cutoff_frequency, nyq_freq/2., order = order)\n",
    "        #df_ar_t_p = np.where(df_ar_t > 0, df_ar_t, 0)\n",
    "        #df_ar_t_n = np.abs(np.where(df_ar_t < 0, df_ar_t, 0))\n",
    "        \n",
    "        df_ar_f = np.gradient(df_ar, axis = 1)\n",
    "        #df_ar_f = butterFilter(df_ar_f, cutoff_frequency, nyq_freq/2., order = order)\n",
    "        #df_ar_f_p = np.where(df_ar_f > 0, df_ar_f, 0)\n",
    "        #df_ar_f_n = np.abs(np.where(df_ar_f < 0, df_ar_f, 0))\n",
    "\n",
    "        #df_ar = np.stack((df_ar_t_p,df_ar_t_n,df_ar_f_p,df_ar_f_n), axis=0)\n",
    "        df_ar = np.stack((df_ar_t,df_ar_f), axis=0)\n",
    "        \n",
    "        #df_ar_t = global_std(df_ar_t)\n",
    "        df_ar = global_std(df_ar)\n",
    "        data = torch.Tensor(df_ar.copy())\n",
    "        #data = torch.Tensor(df_ar_t.copy())\n",
    "        \n",
    "        label_ = self.file_names_bars.iloc[idx, 3]\n",
    "        label = torch.LongTensor([label_])\n",
    "        p_id = self.file_names_bars.iloc[idx, 1]\n",
    "        adr_id = int(str(p_id) + str(self.file_names_bars.iloc[idx, 4]))\n",
    "        adr_id = torch.LongTensor([adr_id])\n",
    "        bars = self.file_names_bars.iloc[idx, 5]\n",
    "        bars = torch.DoubleTensor([bars])\n",
    "        #bars_cat = np.where(bars < 0.5, 0,  np.where(bars < 1.5, 1,  np.where(bars < 2.5, 2,  np.where(bars < 3.5, 3, 4))))\n",
    "        #bars_cat = torch.DoubleTensor([bars])\n",
    "\n",
    "        if self.transform:\n",
    "            data = self.transform(data,label_)\n",
    "            \n",
    "        #data = torch.unsqueeze(data, 0)\n",
    "        return data, bars, adr_id, label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc061517",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataModule to create the datasets and the dataloaders\n",
    "class SpeechDataModule(pl.LightningDataModule):\n",
    "    def __init__(self,train_dataset, test_dataset, batch_size):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.train_dataset = train_dataset\n",
    "        self.test_dataset = test_dataset\n",
    "\n",
    "        self.dataloader_kwargs = {'batch_size' : self.batch_size,\n",
    "                             'shuffle' : True,\n",
    "                             'num_workers' : 4,\n",
    "                             'collate_fn' : PadImage_inf()}\n",
    "        \n",
    "    def setup(self,stage=None):\n",
    "        self.train_dataset = self.train_dataset\n",
    "        self.test_dataset = self.test_dataset\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, shuffle = True, batch_size = self.batch_size, num_workers = 8, collate_fn=PadImage_inf())\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size = len(self.test_dataset), shuffle = False, num_workers = 8, collate_fn=PadImage_inf())\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset , batch_size = self.batch_size, shuffle = False, num_workers = 8, collate_fn=PadImage_inf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d1c88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup the module  \n",
    "train_dataset = SpeechDataset(train_csv_file, train_demo_csv_file, root_dir, transforms_val)\n",
    "test_dataset = SpeechDataset(val_csv_file, val_demo_csv_file, root_dir, transforms_val)\n",
    "print(len(train_dataset), len(test_dataset))\n",
    "data_module = SpeechDataModule(train_dataset, test_dataset, Batch_Size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac293a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "blah = next(iter(data_module.train_dataloader()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0249b41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "blah[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21453028",
   "metadata": {},
   "outputs": [],
   "source": [
    "blah[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548bce8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.display.specshow(blah[0][1][0].numpy().T, x_axis='time', sr=8000, hop_length= 160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcc7f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.display.specshow(blah[0][1][1].numpy().T, x_axis='time', sr=8000, hop_length= 160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44753be",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[43][1][0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691b91c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[10][0][1].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb294e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[43][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce5bbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.display.specshow(train_dataset[42][0][0].numpy().T, x_axis='time', sr=8000, hop_length= 160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9459ce3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.display.specshow(train_dataset[10][0][2].numpy().T, x_axis='time', sr=8000, hop_length= 160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5343a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.display.specshow(train_dataset[23][0][0].numpy().T, x_axis='time', sr=8000,hop_length= 160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f94dce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[23][0][0].numpy().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7d6272",
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.display.specshow(test_dataset[67][0][0].numpy().T, y_axis='mel', x_axis='s', sr=8000, hop_length= 160)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbc3f65",
   "metadata": {},
   "source": [
    "mean = 0.\n",
    "std = 0.\n",
    "nb_samples = 0.\n",
    "max_ = -10000\n",
    "min_ = 10000\n",
    "for data in data_module.train_dataloader():\n",
    "    data = data[0]\n",
    "    batch_samples = data.size(0)\n",
    "    data = data.view(batch_samples, data.size(1), -1)\n",
    "    mean += data.mean(2).sum(0)\n",
    "    std += data.std(2).sum(0)\n",
    "    if data.max() > max_:\n",
    "        max_ = data.max()\n",
    "        \n",
    "    if data.min() < min_:\n",
    "        min_ = data.min()\n",
    "        \n",
    "    nb_samples += batch_samples\n",
    "\n",
    "mean /= nb_samples\n",
    "std /= nb_samples\n",
    "print(mean)\n",
    "print(std)\n",
    "print(max_)\n",
    "print(min_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc912b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictor class performing all the calculations for loss, backpropagation etc        \n",
    "class Speech_Predictor(pl.LightningModule):\n",
    "    def __init__(self, model_size: int):\n",
    "        super(Speech_Predictor,self).__init__()\n",
    "        self.model = FC_Resnet_(num_layers = 2, num_classes = 1) #CNN_short_fc_wide(n_classes=1, n_channels = 1)\n",
    "        self.criterion = torch.nn.MSELoss()#nn.HuberLoss(reduction='mean', delta=1.0)\n",
    "        \n",
    "    def forward(self,x,labels = None, targets_a = None, targets_b = None, lam = None):\n",
    "        output = self.model(x)\n",
    "        loss = 0\n",
    "        if labels is not None:\n",
    "            if lam is not None:\n",
    "                loss =  mixup_criterion(self.criterion, output, targets_a, targets_b, lam)\n",
    "            else:\n",
    "                loss = self.criterion(output,labels)\n",
    "            return loss, output\n",
    "        else:\n",
    "            return output\n",
    "        \n",
    "        \n",
    "    def training_step(self,batch,batch_idx):\n",
    "        X = batch[0]\n",
    "        y = batch[1]\n",
    "        y = y.view((y.shape[0],1))\n",
    "        loss, outputs = self(x = X,labels = y)\n",
    "        \n",
    "        self.log(\"train_loss\",loss,prog_bar = True, logger = True, on_step=True, on_epoch=True)\n",
    "        \n",
    "        return {\"loss\": loss}\n",
    "    \n",
    "    def validation_step(self,batch,batch_idx):\n",
    "        X = batch[0]\n",
    "        y = batch[1]\n",
    "        y = y.view((y.shape[0],1))\n",
    "        i_d = batch[2]\n",
    "        loss, outputs = self(x = X,labels = y)\n",
    "        outputs, _ = groupby_mean(outputs, i_d)\n",
    "        y, y_index = groupby_mean(y.view((y.shape[0],1)), i_d)\n",
    "        y = y.type(torch.DoubleTensor).to(device)\n",
    "        #y = y.type(torch.LongTensor).to(device)\n",
    "        loss = self.criterion(outputs,y)\n",
    "        self.log(\"val_loss\",loss,prog_bar = True, logger = True, on_step=True, on_epoch=True)\n",
    "        \n",
    "        return {\"loss\": loss}\n",
    "    \n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.AdamW(self.parameters(), lr =1.e-4, weight_decay=1e-3)\n",
    "        \n",
    "        lr_scheduler = {\n",
    "        'scheduler': torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=10),\n",
    "        'name': 'SDG_lr',\n",
    "        'monitor': 'val_loss_epoch'}\n",
    "\n",
    "        return [optimizer]# , [lr_scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c018a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the model       \n",
    "model = Speech_Predictor(model_size = model_size_)\n",
    "model.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a47758a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checkpoint and loger definition\n",
    "checkpoint_callback = ModelCheckpoint(dirpath=checkpoint_directory,filename='Small_cnn_best-checkpoint-{epoch:02d}-{val_loss:.2f}_control_AT_bars_speech_nr_v0_',save_top_k=3, verbose =True , monitor = 'val_loss_epoch',mode ='min')\n",
    "logger = TensorBoardLogger(parent_directory + 'lightning_logs', name = 'Speech_small_cnn_AT_Mel_bars_speech_all_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cdb2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if training_on is True:\n",
    "    #Defining the trainer object\n",
    "    trainer = pl.Trainer(logger = logger, callbacks = [checkpoint_callback], max_epochs = epochs, gpus = 1)\n",
    "    trainer.fit(model, data_module)\n",
    "\n",
    "    print('Training finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c318f62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Small_cnn_best-checkpoint-epoch=41-val_loss=0.02_control_AT_bars_speech_nr_v0.ckpt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9134f426",
   "metadata": {},
   "source": [
    "# Model Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77951445",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Models\n",
    "checkpoint_loc_v0 = checkpoint_directory + 'Resnet_best-checkpoint-epoch=63-val_loss=363202.8202_control_AT_regression__speech_mel_grad_tf_10fold_fresh_v0.ckpt'\n",
    "checkpoint_loc_v1 = checkpoint_directory + 'Resnet_best-checkpoint-epoch=72-val_loss=161207.2148_control_AT_regression__speech_mel_grad_tf_10fold_fresh_v1.ckpt'\n",
    "checkpoint_loc_v2 = checkpoint_directory + 'Resnet_best-checkpoint-epoch=89-val_loss=256969.2771_control_AT_regression__speech_mel_grad_tf_10fold_fresh_v2.ckpt'\n",
    "checkpoint_loc_v3 = checkpoint_directory + 'Resnet_best-checkpoint-epoch=93-val_loss=233589.9191_control_AT_regression__speech_mel_grad_tf_10fold_fresh_v3.ckpt'\n",
    "checkpoint_loc_v4 = checkpoint_directory + 'Resnet_best-checkpoint-epoch=93-val_loss=230358.9816_control_AT_regression__speech_mel_grad_tf_10fold_fresh_v4.ckpt'\n",
    "checkpoint_loc_v5 = checkpoint_directory + 'Resnet_best-checkpoint-epoch=23-val_loss=102187.4786_control_AT_regression__speech_mel_grad_tf_10fold_fresh_v5.ckpt'\n",
    "checkpoint_loc_v6 = checkpoint_directory + 'Resnet_best-checkpoint-epoch=22-val_loss=438054.0994_control_AT_regression__speech_mel_grad_tf_10fold_fresh_v6.ckpt'\n",
    "checkpoint_loc_v7 = checkpoint_directory + 'Resnet_best-checkpoint-epoch=43-val_loss=191529.9647_control_AT_regression__speech_mel_grad_tf_10fold_fresh_v7.ckpt'\n",
    "checkpoint_loc_v8 = checkpoint_directory + 'Resnet_best-checkpoint-epoch=93-val_loss=421676.7486_control_AT_regression__speech_mel_grad_tf_10fold_fresh_v8.ckpt'\n",
    "checkpoint_loc_v9 = checkpoint_directory + 'Resnet_best-checkpoint-epoch=10-val_loss=629763.5827_control_AT_regression__speech_mel_grad_tf_10fold_fresh_v9.ckpt'\n",
    "\n",
    "\n",
    "trained_model_v0 = Speech_Predictor.load_from_checkpoint(checkpoint_loc_v0,model_size = model_size_)\n",
    "trained_model_v1 = Speech_Predictor.load_from_checkpoint(checkpoint_loc_v1,model_size = model_size_)\n",
    "trained_model_v2 = Speech_Predictor.load_from_checkpoint(checkpoint_loc_v2,model_size = model_size_)\n",
    "trained_model_v3 = Speech_Predictor.load_from_checkpoint(checkpoint_loc_v3,model_size = model_size_)\n",
    "trained_model_v4 = Speech_Predictor.load_from_checkpoint(checkpoint_loc_v4,model_size = model_size_)\n",
    "trained_model_v5 = Speech_Predictor.load_from_checkpoint(checkpoint_loc_v5,model_size = model_size_)\n",
    "trained_model_v6 = Speech_Predictor.load_from_checkpoint(checkpoint_loc_v6,model_size = model_size_)\n",
    "trained_model_v7 = Speech_Predictor.load_from_checkpoint(checkpoint_loc_v7,model_size = model_size_)\n",
    "trained_model_v8 = Speech_Predictor.load_from_checkpoint(checkpoint_loc_v8,model_size = model_size_)\n",
    "trained_model_v9 = Speech_Predictor.load_from_checkpoint(checkpoint_loc_v9,model_size = model_size_)\n",
    "\n",
    "\n",
    "trained_model_v0.freeze()\n",
    "trained_model_v0.double()\n",
    "trained_model_v1.freeze()\n",
    "trained_model_v1.double()\n",
    "trained_model_v2.freeze()\n",
    "trained_model_v2.double()\n",
    "trained_model_v3.freeze()\n",
    "trained_model_v3.double()\n",
    "trained_model_v4.freeze()\n",
    "trained_model_v4.double()\n",
    "\n",
    "trained_model_v5.freeze()\n",
    "trained_model_v5.double()\n",
    "trained_model_v6.freeze()\n",
    "trained_model_v6.double()\n",
    "trained_model_v7.freeze()\n",
    "trained_model_v7.double()\n",
    "trained_model_v8.freeze()\n",
    "trained_model_v8.double()\n",
    "trained_model_v9.freeze()\n",
    "trained_model_v9.double()\n",
    "\n",
    "models = [trained_model_v0, trained_model_v1, trained_model_v2, trained_model_v3, trained_model_v4,\n",
    "          trained_model_v5, trained_model_v6, trained_model_v7, trained_model_v8, trained_model_v9]\n",
    "\n",
    "\n",
    "#Demographics files\n",
    "\n",
    "val_demo_v0 = pd.read_csv(root_dir + 'val_demo_Mel_severity_cnn_nr2_v0.csv', names=[\"No\",\"P_ID\", \"Sex\", \"Bars\",\"Age\",\"Bars_Speech\",\"Date\"])\n",
    "val_demo_v1 = pd.read_csv(root_dir + 'val_demo_Mel_severity_cnn_nr2_v1.csv', names=[\"No\",\"P_ID\", \"Sex\", \"Bars\",\"Age\", \"Bars_Speech\",\"Date\"])\n",
    "val_demo_v2 = pd.read_csv(root_dir + 'val_demo_Mel_severity_cnn_nr2_v2.csv', names=[\"No\",\"P_ID\", \"Sex\", \"Bars\",\"Age\", \"Bars_Speech\",\"Date\"])\n",
    "val_demo_v3 = pd.read_csv(root_dir + 'val_demo_Mel_severity_cnn_nr2_v3.csv', names=[\"No\",\"P_ID\", \"Sex\", \"Bars\",\"Age\", \"Bars_Speech\",\"Date\"])\n",
    "val_demo_v4 = pd.read_csv(root_dir + 'val_demo_Mel_severity_cnn_nr2_v4.csv', names=[\"No\",\"P_ID\", \"Sex\", \"Bars\",\"Age\", \"Bars_Speech\",\"Date\"])\n",
    "\n",
    "val_demo_v5 = pd.read_csv(root_dir + 'val_demo_Mel_severity_cnn_nr2_v5.csv', names=[\"No\",\"P_ID\", \"Sex\", \"Bars\",\"Age\",\"Bars_Speech\",\"Date\"])\n",
    "val_demo_v6 = pd.read_csv(root_dir + 'val_demo_Mel_severity_cnn_nr2_v6.csv', names=[\"No\",\"P_ID\", \"Sex\", \"Bars\",\"Age\", \"Bars_Speech\",\"Date\"])\n",
    "val_demo_v7 = pd.read_csv(root_dir + 'val_demo_Mel_severity_cnn_nr2_v7.csv', names=[\"No\",\"P_ID\", \"Sex\", \"Bars\",\"Age\", \"Bars_Speech\",\"Date\"])\n",
    "val_demo_v8 = pd.read_csv(root_dir + 'val_demo_Mel_severity_cnn_nr2_v8.csv', names=[\"No\",\"P_ID\", \"Sex\", \"Bars\",\"Age\", \"Bars_Speech\",\"Date\"])\n",
    "val_demo_v9 = pd.read_csv(root_dir + 'val_demo_Mel_severity_cnn_nr2_v9.csv', names=[\"No\",\"P_ID\", \"Sex\", \"Bars\",\"Age\", \"Bars_Speech\",\"Date\"])\n",
    "\n",
    "\n",
    "val_demo_ = [val_demo_v0, val_demo_v1, val_demo_v2, val_demo_v3, val_demo_v4,\n",
    "             val_demo_v5, val_demo_v6, val_demo_v7, val_demo_v8, val_demo_v9]\n",
    "\n",
    "#All validation data sets \n",
    "\n",
    "val_csv_file_v0 = root_dir + 'val_dataset_control_AT_Mel_Spec_2022_noise_red2_severity_v0.csv'\n",
    "val_csv_file_v1 = root_dir + 'val_dataset_control_AT_Mel_Spec_2022_noise_red2_severity_v1.csv'\n",
    "val_csv_file_v2 = root_dir + 'val_dataset_control_AT_Mel_Spec_2022_noise_red2_severity_v2.csv'\n",
    "val_csv_file_v3 = root_dir + 'val_dataset_control_AT_Mel_Spec_2022_noise_red2_severity_v3.csv'\n",
    "val_csv_file_v4 = root_dir + 'val_dataset_control_AT_Mel_Spec_2022_noise_red2_severity_v4.csv'\n",
    "\n",
    "val_csv_file_v5 = root_dir + 'val_dataset_control_AT_Mel_Spec_2022_noise_red2_severity_v5.csv'\n",
    "val_csv_file_v6 = root_dir + 'val_dataset_control_AT_Mel_Spec_2022_noise_red2_severity_v6.csv'\n",
    "val_csv_file_v7 = root_dir + 'val_dataset_control_AT_Mel_Spec_2022_noise_red2_severity_v7.csv'\n",
    "val_csv_file_v8 = root_dir + 'val_dataset_control_AT_Mel_Spec_2022_noise_red2_severity_v8.csv'\n",
    "val_csv_file_v9 = root_dir + 'val_dataset_control_AT_Mel_Spec_2022_noise_red2_severity_v9.csv'\n",
    "\n",
    "\n",
    "test_dataset_v0 = SpeechDataset(val_csv_file_v0, root_dir + 'val_demo_Mel_severity_cnn_nr2_v0.csv', root_dir,transforms_val)\n",
    "test_dataset_v1 = SpeechDataset(val_csv_file_v1, root_dir + 'val_demo_Mel_severity_cnn_nr2_v1.csv', root_dir,transforms_val)\n",
    "test_dataset_v2 = SpeechDataset(val_csv_file_v2, root_dir + 'val_demo_Mel_severity_cnn_nr2_v2.csv', root_dir,transforms_val)\n",
    "test_dataset_v3 = SpeechDataset(val_csv_file_v3, root_dir + 'val_demo_Mel_severity_cnn_nr2_v3.csv', root_dir,transforms_val)\n",
    "test_dataset_v4 = SpeechDataset(val_csv_file_v4, root_dir + 'val_demo_Mel_severity_cnn_nr2_v4.csv', root_dir,transforms_val)\n",
    "\n",
    "test_dataset_v5 = SpeechDataset(val_csv_file_v5, root_dir + 'val_demo_Mel_severity_cnn_nr2_v5.csv', root_dir,transforms_val)\n",
    "test_dataset_v6 = SpeechDataset(val_csv_file_v6, root_dir + 'val_demo_Mel_severity_cnn_nr2_v6.csv', root_dir,transforms_val)\n",
    "test_dataset_v7 = SpeechDataset(val_csv_file_v7, root_dir + 'val_demo_Mel_severity_cnn_nr2_v7.csv', root_dir,transforms_val)\n",
    "test_dataset_v8 = SpeechDataset(val_csv_file_v8, root_dir + 'val_demo_Mel_severity_cnn_nr2_v8.csv', root_dir,transforms_val)\n",
    "test_dataset_v9 = SpeechDataset(val_csv_file_v9, root_dir + 'val_demo_Mel_severity_cnn_nr2_v9.csv', root_dir,transforms_val)\n",
    "\n",
    "all_data = [test_dataset_v0, test_dataset_v1, test_dataset_v2, test_dataset_v3, test_dataset_v4,\n",
    "            test_dataset_v5, test_dataset_v6, test_dataset_v7, test_dataset_v8, test_dataset_v9]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cc34ea",
   "metadata": {},
   "source": [
    "#Models\n",
    "checkpoint_loc_v0 = checkpoint_directory + 'Resnet_best-checkpoint-epoch=60-val_loss=349444.0286_control_AT_regression__speech_mel_grad_tf_10fold_fresh_v0.ckpt'\n",
    "checkpoint_loc_v1 = checkpoint_directory + 'Resnet_best-checkpoint-epoch=56-val_loss=155868.3017_control_AT_regression__speech_mel_grad_tf_10fold_fresh_v1.ckpt'\n",
    "checkpoint_loc_v2 = checkpoint_directory + 'Resnet_best-checkpoint-epoch=38-val_loss=200963.5426_control_AT_regression__speech_mel_grad_tf_10fold_fresh_v2.ckpt'\n",
    "checkpoint_loc_v3 = checkpoint_directory + 'Resnet_best-checkpoint-epoch=89-val_loss=167465.8954_control_AT_regression__speech_mel_grad_tf_10fold_fresh_v3.ckpt'\n",
    "checkpoint_loc_v4 = checkpoint_directory + 'Resnet_best-checkpoint-epoch=49-val_loss=163618.2469_control_AT_regression__speech_mel_grad_tf_10fold_fresh_v4.ckpt'\n",
    "checkpoint_loc_v5 = checkpoint_directory + 'Resnet_best-checkpoint-epoch=36-val_loss=155116.7022_control_AT_regression__speech_mel_grad_tf_10fold_fresh_v5.ckpt'\n",
    "checkpoint_loc_v6 = checkpoint_directory + 'Resnet_best-checkpoint-epoch=21-val_loss=404394.1621_control_AT_regression__speech_mel_grad_tf_10fold_fresh_v6.ckpt'\n",
    "checkpoint_loc_v7 = checkpoint_directory + 'Resnet_best-checkpoint-epoch=87-val_loss=220144.4472_control_AT_regression__speech_mel_grad_tf_10fold_fresh_v7.ckpt'\n",
    "checkpoint_loc_v8 = checkpoint_directory + 'Resnet_best-checkpoint-epoch=56-val_loss=147005.0093_control_AT_regression__speech_mel_grad_tf_10fold_fresh_v8.ckpt'\n",
    "checkpoint_loc_v9 = checkpoint_directory + 'Resnet_best-checkpoint-epoch=91-val_loss=271779.7988_control_AT_regression__speech_mel_grad_tf_10fold_fresh_v9.ckpt'\n",
    "\n",
    "\n",
    "\n",
    "trained_model_v0 = Speech_Predictor.load_from_checkpoint(checkpoint_loc_v0,model_size = model_size_)\n",
    "trained_model_v1 = Speech_Predictor.load_from_checkpoint(checkpoint_loc_v1,model_size = model_size_)\n",
    "trained_model_v2 = Speech_Predictor.load_from_checkpoint(checkpoint_loc_v2,model_size = model_size_)\n",
    "trained_model_v3 = Speech_Predictor.load_from_checkpoint(checkpoint_loc_v3,model_size = model_size_)\n",
    "trained_model_v4 = Speech_Predictor.load_from_checkpoint(checkpoint_loc_v4,model_size = model_size_)\n",
    "trained_model_v5 = Speech_Predictor.load_from_checkpoint(checkpoint_loc_v5,model_size = model_size_)\n",
    "trained_model_v6 = Speech_Predictor.load_from_checkpoint(checkpoint_loc_v6,model_size = model_size_)\n",
    "trained_model_v7 = Speech_Predictor.load_from_checkpoint(checkpoint_loc_v7,model_size = model_size_)\n",
    "trained_model_v8 = Speech_Predictor.load_from_checkpoint(checkpoint_loc_v8,model_size = model_size_)\n",
    "trained_model_v9 = Speech_Predictor.load_from_checkpoint(checkpoint_loc_v9,model_size = model_size_)\n",
    "\n",
    "\n",
    "trained_model_v0.freeze()\n",
    "trained_model_v0.double()\n",
    "trained_model_v1.freeze()\n",
    "trained_model_v1.double()\n",
    "trained_model_v2.freeze()\n",
    "trained_model_v2.double()\n",
    "trained_model_v3.freeze()\n",
    "trained_model_v3.double()\n",
    "trained_model_v4.freeze()\n",
    "trained_model_v4.double()\n",
    "\n",
    "trained_model_v5.freeze()\n",
    "trained_model_v5.double()\n",
    "trained_model_v6.freeze()\n",
    "trained_model_v6.double()\n",
    "trained_model_v7.freeze()\n",
    "trained_model_v7.double()\n",
    "trained_model_v8.freeze()\n",
    "trained_model_v8.double()\n",
    "trained_model_v9.freeze()\n",
    "trained_model_v9.double()\n",
    "\n",
    "models = [trained_model_v0, trained_model_v1, trained_model_v2, trained_model_v3, trained_model_v4,\n",
    "          trained_model_v5, trained_model_v6, trained_model_v7, trained_model_v8, trained_model_v9]\n",
    "\n",
    "\n",
    "#Demographics files\n",
    "\n",
    "val_demo_v0 = pd.read_csv(root_dir + 'val_demo_Mel_severity_cnn_nr2_v0.csv', names=[\"No\",\"P_ID\", \"Sex\", \"Bars\",\"Age\",\"Bars_Speech\",\"Date\"])\n",
    "val_demo_v1 = pd.read_csv(root_dir + 'val_demo_Mel_severity_cnn_nr2_v1.csv', names=[\"No\",\"P_ID\", \"Sex\", \"Bars\",\"Age\", \"Bars_Speech\",\"Date\"])\n",
    "val_demo_v2 = pd.read_csv(root_dir + 'val_demo_Mel_severity_cnn_nr2_v2.csv', names=[\"No\",\"P_ID\", \"Sex\", \"Bars\",\"Age\", \"Bars_Speech\",\"Date\"])\n",
    "val_demo_v3 = pd.read_csv(root_dir + 'val_demo_Mel_severity_cnn_nr2_v3.csv', names=[\"No\",\"P_ID\", \"Sex\", \"Bars\",\"Age\", \"Bars_Speech\",\"Date\"])\n",
    "val_demo_v4 = pd.read_csv(root_dir + 'val_demo_Mel_severity_cnn_nr2_v4.csv', names=[\"No\",\"P_ID\", \"Sex\", \"Bars\",\"Age\", \"Bars_Speech\",\"Date\"])\n",
    "\n",
    "val_demo_v5 = pd.read_csv(root_dir + 'val_demo_Mel_severity_cnn_nr2_v5.csv', names=[\"No\",\"P_ID\", \"Sex\", \"Bars\",\"Age\",\"Bars_Speech\",\"Date\"])\n",
    "val_demo_v6 = pd.read_csv(root_dir + 'val_demo_Mel_severity_cnn_nr2_v6.csv', names=[\"No\",\"P_ID\", \"Sex\", \"Bars\",\"Age\", \"Bars_Speech\",\"Date\"])\n",
    "val_demo_v7 = pd.read_csv(root_dir + 'val_demo_Mel_severity_cnn_nr2_v7.csv', names=[\"No\",\"P_ID\", \"Sex\", \"Bars\",\"Age\", \"Bars_Speech\",\"Date\"])\n",
    "val_demo_v8 = pd.read_csv(root_dir + 'val_demo_Mel_severity_cnn_nr2_v8.csv', names=[\"No\",\"P_ID\", \"Sex\", \"Bars\",\"Age\", \"Bars_Speech\",\"Date\"])\n",
    "val_demo_v9 = pd.read_csv(root_dir + 'val_demo_Mel_severity_cnn_nr2_v9.csv', names=[\"No\",\"P_ID\", \"Sex\", \"Bars\",\"Age\", \"Bars_Speech\",\"Date\"])\n",
    "\n",
    "\n",
    "val_demo_ = [val_demo_v0, val_demo_v1, val_demo_v2, val_demo_v3, val_demo_v4,\n",
    "             val_demo_v5, val_demo_v6, val_demo_v7, val_demo_v8, val_demo_v9]\n",
    "\n",
    "#All validation data sets \n",
    "\n",
    "val_csv_file_v0 = root_dir + 'val_dataset_control_AT_Mel_Spec_2022_noise_red2_severity_v0.csv'\n",
    "val_csv_file_v1 = root_dir + 'val_dataset_control_AT_Mel_Spec_2022_noise_red2_severity_v1.csv'\n",
    "val_csv_file_v2 = root_dir + 'val_dataset_control_AT_Mel_Spec_2022_noise_red2_severity_v2.csv'\n",
    "val_csv_file_v3 = root_dir + 'val_dataset_control_AT_Mel_Spec_2022_noise_red2_severity_v3.csv'\n",
    "val_csv_file_v4 = root_dir + 'val_dataset_control_AT_Mel_Spec_2022_noise_red2_severity_v4.csv'\n",
    "\n",
    "val_csv_file_v5 = root_dir + 'val_dataset_control_AT_Mel_Spec_2022_noise_red2_severity_v5.csv'\n",
    "val_csv_file_v6 = root_dir + 'val_dataset_control_AT_Mel_Spec_2022_noise_red2_severity_v6.csv'\n",
    "val_csv_file_v7 = root_dir + 'val_dataset_control_AT_Mel_Spec_2022_noise_red2_severity_v7.csv'\n",
    "val_csv_file_v8 = root_dir + 'val_dataset_control_AT_Mel_Spec_2022_noise_red2_severity_v8.csv'\n",
    "val_csv_file_v9 = root_dir + 'val_dataset_control_AT_Mel_Spec_2022_noise_red2_severity_v9.csv'\n",
    "\n",
    "\n",
    "test_dataset_v0 = SpeechDataset(val_csv_file_v0, root_dir + 'val_demo_Mel_severity_cnn_nr2_v0.csv', root_dir,transforms_val)\n",
    "test_dataset_v1 = SpeechDataset(val_csv_file_v1, root_dir + 'val_demo_Mel_severity_cnn_nr2_v1.csv', root_dir,transforms_val)\n",
    "test_dataset_v2 = SpeechDataset(val_csv_file_v2, root_dir + 'val_demo_Mel_severity_cnn_nr2_v2.csv', root_dir,transforms_val)\n",
    "test_dataset_v3 = SpeechDataset(val_csv_file_v3, root_dir + 'val_demo_Mel_severity_cnn_nr2_v3.csv', root_dir,transforms_val)\n",
    "test_dataset_v4 = SpeechDataset(val_csv_file_v4, root_dir + 'val_demo_Mel_severity_cnn_nr2_v4.csv', root_dir,transforms_val)\n",
    "\n",
    "test_dataset_v5 = SpeechDataset(val_csv_file_v5, root_dir + 'val_demo_Mel_severity_cnn_nr2_v5.csv', root_dir,transforms_val)\n",
    "test_dataset_v6 = SpeechDataset(val_csv_file_v6, root_dir + 'val_demo_Mel_severity_cnn_nr2_v6.csv', root_dir,transforms_val)\n",
    "test_dataset_v7 = SpeechDataset(val_csv_file_v7, root_dir + 'val_demo_Mel_severity_cnn_nr2_v7.csv', root_dir,transforms_val)\n",
    "test_dataset_v8 = SpeechDataset(val_csv_file_v8, root_dir + 'val_demo_Mel_severity_cnn_nr2_v8.csv', root_dir,transforms_val)\n",
    "test_dataset_v9 = SpeechDataset(val_csv_file_v9, root_dir + 'val_demo_Mel_severity_cnn_nr2_v9.csv', root_dir,transforms_val)\n",
    "\n",
    "all_data = [test_dataset_v0, test_dataset_v1, test_dataset_v2, test_dataset_v3, test_dataset_v4,\n",
    "            test_dataset_v5, test_dataset_v6, test_dataset_v7, test_dataset_v8, test_dataset_v9]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6138358f",
   "metadata": {},
   "source": [
    "#Models\n",
    "checkpoint_loc_v0 = checkpoint_directory + 'Resnet_best-checkpoint-epoch=83-val_loss=521.5691_control_AT_regression__speech_mel_grad_tf_10fold_fresh_v0.ckpt'\n",
    "checkpoint_loc_v1 = checkpoint_directory + 'Resnet_best-checkpoint-epoch=83-val_loss=310.9604_control_AT_regression__speech_mel_grad_tf_10fold_fresh_v1.ckpt'\n",
    "checkpoint_loc_v2 = checkpoint_directory + 'Resnet_best-checkpoint-epoch=67-val_loss=336.1748_control_AT_regression__speech_mel_grad_tf_10fold_fresh_v2.ckpt'\n",
    "checkpoint_loc_v3 = checkpoint_directory + 'Resnet_best-checkpoint-epoch=92-val_loss=412.6540_control_AT_regression__speech_mel_grad_tf_10fold_fresh_v3.ckpt'\n",
    "checkpoint_loc_v4 = checkpoint_directory + 'Resnet_best-checkpoint-epoch=74-val_loss=372.4298_control_AT_regression__speech_mel_grad_tf_10fold_fresh_v4.ckpt'\n",
    "checkpoint_loc_v5 = checkpoint_directory + 'Resnet_best-checkpoint-epoch=41-val_loss=424.3832_control_AT_regression__speech_mel_grad_tf_10fold_fresh_v5.ckpt'\n",
    "checkpoint_loc_v6 = checkpoint_directory + 'Resnet_best-checkpoint-epoch=68-val_loss=548.6907_control_AT_regression__speech_mel_grad_tf_10fold_fresh_v6.ckpt'\n",
    "checkpoint_loc_v7 = checkpoint_directory + 'Resnet_best-checkpoint-epoch=81-val_loss=422.9223_control_AT_regression__speech_mel_grad_tf_10fold_fresh_v7.ckpt'\n",
    "checkpoint_loc_v8 = checkpoint_directory + 'Resnet_best-checkpoint-epoch=60-val_loss=349.6113_control_AT_regression__speech_mel_grad_tf_10fold_fresh_v8.ckpt'\n",
    "checkpoint_loc_v9 = checkpoint_directory + 'Resnet_best-checkpoint-epoch=95-val_loss=463.4654_control_AT_regression__speech_mel_grad_tf_10fold_fresh_v9.ckpt'\n",
    "\n",
    "\n",
    "\n",
    "trained_model_v0 = Speech_Predictor.load_from_checkpoint(checkpoint_loc_v0,model_size = model_size_)\n",
    "trained_model_v1 = Speech_Predictor.load_from_checkpoint(checkpoint_loc_v1,model_size = model_size_)\n",
    "trained_model_v2 = Speech_Predictor.load_from_checkpoint(checkpoint_loc_v2,model_size = model_size_)\n",
    "trained_model_v3 = Speech_Predictor.load_from_checkpoint(checkpoint_loc_v3,model_size = model_size_)\n",
    "trained_model_v4 = Speech_Predictor.load_from_checkpoint(checkpoint_loc_v4,model_size = model_size_)\n",
    "trained_model_v5 = Speech_Predictor.load_from_checkpoint(checkpoint_loc_v5,model_size = model_size_)\n",
    "trained_model_v6 = Speech_Predictor.load_from_checkpoint(checkpoint_loc_v6,model_size = model_size_)\n",
    "trained_model_v7 = Speech_Predictor.load_from_checkpoint(checkpoint_loc_v7,model_size = model_size_)\n",
    "trained_model_v8 = Speech_Predictor.load_from_checkpoint(checkpoint_loc_v8,model_size = model_size_)\n",
    "trained_model_v9 = Speech_Predictor.load_from_checkpoint(checkpoint_loc_v9,model_size = model_size_)\n",
    "\n",
    "\n",
    "trained_model_v0.freeze()\n",
    "trained_model_v0.double()\n",
    "trained_model_v1.freeze()\n",
    "trained_model_v1.double()\n",
    "trained_model_v2.freeze()\n",
    "trained_model_v2.double()\n",
    "trained_model_v3.freeze()\n",
    "trained_model_v3.double()\n",
    "trained_model_v4.freeze()\n",
    "trained_model_v4.double()\n",
    "\n",
    "trained_model_v5.freeze()\n",
    "trained_model_v5.double()\n",
    "trained_model_v6.freeze()\n",
    "trained_model_v6.double()\n",
    "trained_model_v7.freeze()\n",
    "trained_model_v7.double()\n",
    "trained_model_v8.freeze()\n",
    "trained_model_v8.double()\n",
    "trained_model_v9.freeze()\n",
    "trained_model_v9.double()\n",
    "\n",
    "models = [trained_model_v0, trained_model_v1, trained_model_v2, trained_model_v3, trained_model_v4,\n",
    "          trained_model_v5, trained_model_v6, trained_model_v7, trained_model_v8, trained_model_v9]\n",
    "\n",
    "\n",
    "#Demographics files\n",
    "\n",
    "val_demo_v0 = pd.read_csv(root_dir + 'val_demo_Mel_severity_cnn_nr2_v0.csv', names=[\"No\",\"P_ID\", \"Sex\", \"Bars\",\"Age\",\"Bars_Speech\",\"Date\"])\n",
    "val_demo_v1 = pd.read_csv(root_dir + 'val_demo_Mel_severity_cnn_nr2_v1.csv', names=[\"No\",\"P_ID\", \"Sex\", \"Bars\",\"Age\", \"Bars_Speech\",\"Date\"])\n",
    "val_demo_v2 = pd.read_csv(root_dir + 'val_demo_Mel_severity_cnn_nr2_v2.csv', names=[\"No\",\"P_ID\", \"Sex\", \"Bars\",\"Age\", \"Bars_Speech\",\"Date\"])\n",
    "val_demo_v3 = pd.read_csv(root_dir + 'val_demo_Mel_severity_cnn_nr2_v3.csv', names=[\"No\",\"P_ID\", \"Sex\", \"Bars\",\"Age\", \"Bars_Speech\",\"Date\"])\n",
    "val_demo_v4 = pd.read_csv(root_dir + 'val_demo_Mel_severity_cnn_nr2_v4.csv', names=[\"No\",\"P_ID\", \"Sex\", \"Bars\",\"Age\", \"Bars_Speech\",\"Date\"])\n",
    "\n",
    "val_demo_v5 = pd.read_csv(root_dir + 'val_demo_Mel_severity_cnn_nr2_v5.csv', names=[\"No\",\"P_ID\", \"Sex\", \"Bars\",\"Age\",\"Bars_Speech\",\"Date\"])\n",
    "val_demo_v6 = pd.read_csv(root_dir + 'val_demo_Mel_severity_cnn_nr2_v6.csv', names=[\"No\",\"P_ID\", \"Sex\", \"Bars\",\"Age\", \"Bars_Speech\",\"Date\"])\n",
    "val_demo_v7 = pd.read_csv(root_dir + 'val_demo_Mel_severity_cnn_nr2_v7.csv', names=[\"No\",\"P_ID\", \"Sex\", \"Bars\",\"Age\", \"Bars_Speech\",\"Date\"])\n",
    "val_demo_v8 = pd.read_csv(root_dir + 'val_demo_Mel_severity_cnn_nr2_v8.csv', names=[\"No\",\"P_ID\", \"Sex\", \"Bars\",\"Age\", \"Bars_Speech\",\"Date\"])\n",
    "val_demo_v9 = pd.read_csv(root_dir + 'val_demo_Mel_severity_cnn_nr2_v9.csv', names=[\"No\",\"P_ID\", \"Sex\", \"Bars\",\"Age\", \"Bars_Speech\",\"Date\"])\n",
    "\n",
    "\n",
    "val_demo_ = [val_demo_v0, val_demo_v1, val_demo_v2, val_demo_v3, val_demo_v4,\n",
    "             val_demo_v5, val_demo_v6, val_demo_v7, val_demo_v8, val_demo_v9]\n",
    "\n",
    "#All validation data sets \n",
    "\n",
    "val_csv_file_v0 = root_dir + 'val_dataset_control_AT_Mel_Spec_2022_noise_red2_severity_v0.csv'\n",
    "val_csv_file_v1 = root_dir + 'val_dataset_control_AT_Mel_Spec_2022_noise_red2_severity_v1.csv'\n",
    "val_csv_file_v2 = root_dir + 'val_dataset_control_AT_Mel_Spec_2022_noise_red2_severity_v2.csv'\n",
    "val_csv_file_v3 = root_dir + 'val_dataset_control_AT_Mel_Spec_2022_noise_red2_severity_v3.csv'\n",
    "val_csv_file_v4 = root_dir + 'val_dataset_control_AT_Mel_Spec_2022_noise_red2_severity_v4.csv'\n",
    "\n",
    "val_csv_file_v5 = root_dir + 'val_dataset_control_AT_Mel_Spec_2022_noise_red2_severity_v5.csv'\n",
    "val_csv_file_v6 = root_dir + 'val_dataset_control_AT_Mel_Spec_2022_noise_red2_severity_v6.csv'\n",
    "val_csv_file_v7 = root_dir + 'val_dataset_control_AT_Mel_Spec_2022_noise_red2_severity_v7.csv'\n",
    "val_csv_file_v8 = root_dir + 'val_dataset_control_AT_Mel_Spec_2022_noise_red2_severity_v8.csv'\n",
    "val_csv_file_v9 = root_dir + 'val_dataset_control_AT_Mel_Spec_2022_noise_red2_severity_v9.csv'\n",
    "\n",
    "\n",
    "test_dataset_v0 = SpeechDataset(val_csv_file_v0, root_dir + 'val_demo_Mel_severity_cnn_nr2_v0.csv', root_dir,transforms_val)\n",
    "test_dataset_v1 = SpeechDataset(val_csv_file_v1, root_dir + 'val_demo_Mel_severity_cnn_nr2_v1.csv', root_dir,transforms_val)\n",
    "test_dataset_v2 = SpeechDataset(val_csv_file_v2, root_dir + 'val_demo_Mel_severity_cnn_nr2_v2.csv', root_dir,transforms_val)\n",
    "test_dataset_v3 = SpeechDataset(val_csv_file_v3, root_dir + 'val_demo_Mel_severity_cnn_nr2_v3.csv', root_dir,transforms_val)\n",
    "test_dataset_v4 = SpeechDataset(val_csv_file_v4, root_dir + 'val_demo_Mel_severity_cnn_nr2_v4.csv', root_dir,transforms_val)\n",
    "\n",
    "test_dataset_v5 = SpeechDataset(val_csv_file_v5, root_dir + 'val_demo_Mel_severity_cnn_nr2_v5.csv', root_dir,transforms_val)\n",
    "test_dataset_v6 = SpeechDataset(val_csv_file_v6, root_dir + 'val_demo_Mel_severity_cnn_nr2_v6.csv', root_dir,transforms_val)\n",
    "test_dataset_v7 = SpeechDataset(val_csv_file_v7, root_dir + 'val_demo_Mel_severity_cnn_nr2_v7.csv', root_dir,transforms_val)\n",
    "test_dataset_v8 = SpeechDataset(val_csv_file_v8, root_dir + 'val_demo_Mel_severity_cnn_nr2_v8.csv', root_dir,transforms_val)\n",
    "test_dataset_v9 = SpeechDataset(val_csv_file_v9, root_dir + 'val_demo_Mel_severity_cnn_nr2_v9.csv', root_dir,transforms_val)\n",
    "\n",
    "all_data = [test_dataset_v0, test_dataset_v1, test_dataset_v2, test_dataset_v3, test_dataset_v4,\n",
    "            test_dataset_v5, test_dataset_v6, test_dataset_v7, test_dataset_v8, test_dataset_v9]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f11846b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the output of the models\n",
    "val_demo__ = []\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "    test_dataset = all_data[i]\n",
    "    trained_model = models[i]\n",
    "    val_demo = val_demo_[i]\n",
    "    bars_pred = []\n",
    "    y_label_list =[]\n",
    "    bars_obsr_list =[]\n",
    "    date_list = []\n",
    "    for sample in test_dataset:\n",
    "        X_s, bars,date_, y_label = sample\n",
    "        \n",
    "        #if X_s.shape[1]< 50:\n",
    "        #    bars_pred.append(np.nan)\n",
    "        #    bars_obsr_list.append(np.nan)\n",
    "        #    continue\n",
    "        \n",
    "        input_ = X_s.double().unsqueeze(0)\n",
    "        output = trained_model(input_)\n",
    "        \n",
    "        val_demo.loc[(val_demo.Date == date_[0].detach().cpu().numpy()),'Label'] = y_label[0].detach().cpu().numpy()\n",
    "        bars_pred.append(output[0][0].detach().cpu().numpy()/1000.)\n",
    "        bars_obsr_list.append(bars[0].detach().cpu().numpy())\n",
    "        #bars_pred.append(output[0][0].detach().cpu().numpy())\n",
    "        #bars_obsr_list.append(bars[0].detach().cpu().numpy())\n",
    "        \n",
    "        #y_label_list.append(y_label[0].detach().cpu().numpy())\n",
    "        date_list.append(date_[0].detach().cpu().numpy())\n",
    "    \n",
    "    val_demo.loc[(val_demo.Label == 0),'Bars_Speech']= 0.\n",
    "    #val_demo = val_demo[val_demo['Label'] == 1.]\n",
    "    val_demo = val_demo[val_demo['Bars_Speech']>= 0.]\n",
    "    val_demo = val_demo[val_demo['Bars_Speech'].notna()]\n",
    "    print(len(val_demo),len(bars_pred))\n",
    "    val_demo.loc[val_demo['Bars_Speech'].notna(), \"BARS_pred\"] = bars_pred\n",
    "    val_demo.loc[val_demo['Bars_Speech'].notna(), \"BARS_obsr\"] = bars_obsr_list\n",
    "    val_demo__.append(val_demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8ea786",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_demo__[0]['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe56693",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_demo__[0]['BARS_obsr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448846f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_demo__[0]['Bars_Speech']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9760b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#val_demo__ = [val_demo_[0], val_demo_[1], val_demo_[2], val_demo_[3], val_demo_[4],\n",
    "#              val_demo_[5], val_demo_[6], val_demo_[7], val_demo_[8], val_demo_[9]]\n",
    "val_demo_all = pd.concat(val_demo__, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbe53b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ee534d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_demo_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0641988f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "val_demo_bars = val_demo_all[['P_ID','Sex','Label', 'Age','BARS_obsr', 'BARS_pred','Date']]\n",
    "#val_demo_bars = val_demo_bars[val_demo_bars['BARS_obsr'].notna()]\n",
    "#val_demo_bars = val_demo_bars[val_demo_bars['BARS_obsr'] >= 0]\n",
    "val_demo_bars = val_demo_bars[val_demo_bars['Label'] == 1]\n",
    "val_demo_bars_male = val_demo_bars[val_demo_bars['Sex'] == \"M\"]\n",
    "val_demo_bars_female = val_demo_bars[val_demo_bars['Sex'] == \"F\"]\n",
    "val_demo_bars_male[\"ID_ranked\"] = val_demo_bars_male[\"P_ID\"]#.rank()-1\n",
    "val_demo_bars_female[\"ID_ranked\"] = val_demo_bars_female[\"P_ID\"]#.rank()-1\n",
    "val_demo_bars = val_demo_bars[['P_ID','Label', 'Age','BARS_obsr', 'BARS_pred', 'Date']].astype('float64')\n",
    "val_demo_bars = val_demo_bars.groupby(['Date'], as_index = False).median()\n",
    "\n",
    "\n",
    "val_demo_bars_male = val_demo_bars_male[['ID_ranked','Label', 'Age','BARS_obsr', 'BARS_pred','Date']]\n",
    "val_demo_bars_male = val_demo_bars_male.astype('float64')\n",
    "\n",
    "val_demo_bars_female = val_demo_bars_female[['ID_ranked','Label', 'Age','BARS_obsr', 'BARS_pred','Date']]\n",
    "val_demo_bars_female = val_demo_bars_female.astype('float64')\n",
    "\n",
    "\n",
    "val_demo_bars_male_lower68 = val_demo_bars_male.groupby(['Date'], as_index = False).quantile(0.159)\n",
    "val_demo_bars_female_lower68 = val_demo_bars_female.groupby(['Date'], as_index = False).quantile(0.159)\n",
    "\n",
    "val_demo_bars_male_upper68 = val_demo_bars_male.groupby(['Date'], as_index = False).quantile(0.841)\n",
    "val_demo_bars_female_upper68 = val_demo_bars_female.groupby(['Date'], as_index = False).quantile(0.841)\n",
    "\n",
    "val_demo_bars_male = val_demo_bars_male.groupby(['Date'], as_index = False).median()\n",
    "val_demo_bars_female = val_demo_bars_female.groupby(['Date'], as_index = False).median()\n",
    "\n",
    "cmap = plt.get_cmap('gray')\n",
    "new_cmap = truncate_colormap(cmap, 0.2, 1)\n",
    "\n",
    "val_demo_bars_ = pd.concat([val_demo_bars_male, val_demo_bars_female], ignore_index=True)\n",
    "#sns.kdeplot(x=val_demo_bars_['BARS_obsr'], y=val_demo_bars_['BARS_pred'], cmap=new_cmap, shade=True, bw_adjust=.65, clip=([-0.5,30],[-0.5, 30.0]))\n",
    "\n",
    "ax.scatter(val_demo_bars_male['BARS_obsr'], val_demo_bars_male['BARS_pred'], c = 'red', marker = 'o', s = 2*val_demo_bars_male['Age'])\n",
    "ax.scatter(val_demo_bars_female['BARS_obsr'], val_demo_bars_female['BARS_pred'], c = 'red', marker = 'x', s = 2* val_demo_bars_female['Age'])\n",
    "\n",
    "###########\n",
    "val_demo_bars = val_demo_all[['P_ID','Sex','Label', 'Age','BARS_obsr', 'BARS_pred','Date']]\n",
    "val_demo_bars = val_demo_bars[val_demo_bars['Label'] == 0]\n",
    "val_demo_bars_male = val_demo_bars[val_demo_bars['Sex'] == \"M\"]\n",
    "val_demo_bars_female = val_demo_bars[val_demo_bars['Sex'] == \"F\"]\n",
    "val_demo_bars_male[\"ID_ranked\"] = val_demo_bars_male[\"P_ID\"]#.rank()-1\n",
    "val_demo_bars_female[\"ID_ranked\"] = val_demo_bars_female[\"P_ID\"]#.rank()-1\n",
    "val_demo_bars = val_demo_bars[['P_ID','Label', 'Age','BARS_obsr', 'BARS_pred', 'Date']].astype('float64')\n",
    "val_demo_bars = val_demo_bars.groupby(['Date'], as_index = False).median()\n",
    "\n",
    "\n",
    "val_demo_bars_male = val_demo_bars_male[['ID_ranked','Label', 'Age','BARS_obsr', 'BARS_pred','Date']]\n",
    "val_demo_bars_male = val_demo_bars_male.astype('float64')\n",
    "\n",
    "val_demo_bars_female = val_demo_bars_female[['ID_ranked','Label', 'Age','BARS_obsr', 'BARS_pred','Date']]\n",
    "val_demo_bars_female = val_demo_bars_female.astype('float64')\n",
    "\n",
    "\n",
    "val_demo_bars_male_lower68 = val_demo_bars_male.groupby(['Date'], as_index = False).quantile(0.159)\n",
    "val_demo_bars_female_lower68 = val_demo_bars_female.groupby(['Date'], as_index = False).quantile(0.159)\n",
    "\n",
    "val_demo_bars_male_upper68 = val_demo_bars_male.groupby(['Date'], as_index = False).quantile(0.841)\n",
    "val_demo_bars_female_upper68 = val_demo_bars_female.groupby(['Date'], as_index = False).quantile(0.841)\n",
    "\n",
    "val_demo_bars_male = val_demo_bars_male.groupby(['Date'], as_index = False).median()\n",
    "val_demo_bars_female = val_demo_bars_female.groupby(['Date'], as_index = False).median()\n",
    "\n",
    "\n",
    "val_demo_bars_ = pd.concat([val_demo_bars_male, val_demo_bars_female], ignore_index=True)\n",
    "#sns.kdeplot(x=val_demo_bars_['BARS_obsr'], y=val_demo_bars_['BARS_pred'], cmap=new_cmap, shade=True, bw_adjust=.65, clip=([-0.5,30],[-0.5, 30.0]))\n",
    "\n",
    "ax.scatter(val_demo_bars_male['BARS_obsr'], val_demo_bars_male['BARS_pred'], c = 'blue', marker = 'o', s = 2*val_demo_bars_male['Age'])\n",
    "ax.scatter(val_demo_bars_female['BARS_obsr'], val_demo_bars_female['BARS_pred'], c = 'blue', marker = 'x', s = 2* val_demo_bars_female['Age'])\n",
    "\n",
    "\n",
    "######################\n",
    "val_demo_bars = val_demo_all[['P_ID','Sex','Label', 'Age','BARS_obsr', 'BARS_pred','Date']]\n",
    "val_demo_bars_male = val_demo_bars[val_demo_bars['Sex'] == \"M\"]\n",
    "val_demo_bars_female = val_demo_bars[val_demo_bars['Sex'] == \"F\"]\n",
    "val_demo_bars_male[\"ID_ranked\"] = val_demo_bars_male[\"P_ID\"]#.rank()-1\n",
    "val_demo_bars_female[\"ID_ranked\"] = val_demo_bars_female[\"P_ID\"]#.rank()-1\n",
    "val_demo_bars = val_demo_bars[['P_ID','Label', 'Age','BARS_obsr', 'BARS_pred', 'Date']].astype('float64')\n",
    "val_demo_bars = val_demo_bars.groupby(['Date'], as_index = False).median()\n",
    "#val_demo_bars = val_demo_bars.astype('float64')\n",
    "\n",
    "cmap = plt.get_cmap('gray')\n",
    "new_cmap = truncate_colormap(cmap, 0.2, 1)\n",
    "#sns.kdeplot(x=val_demo_bars_['BARS_obsr'], y=val_demo_bars_['BARS_pred'], cmap=new_cmap, shade=True, bw_adjust=.65, clip=([-0.5,30],[-0.5, 30.0]))\n",
    "\n",
    "\n",
    "ax.plot([0, 4], [0, 4],color = 'k',linewidth = 5,linestyle ='-.')\n",
    "\n",
    "ax.fill_between([0,4], [-0.35, 4 -0.35], [0.35, 4 + 0.35], color='k', alpha=.1)\n",
    "\n",
    "z, V = np.polyfit(val_demo_bars['BARS_obsr'], val_demo_bars['BARS_pred'], 1, cov=True)\n",
    "p = np.poly1d(z)\n",
    "slope_err = np.sqrt(V[0][0])\n",
    "inter_err = np.sqrt(V[1][1])\n",
    "plt.plot(range(5),p(range(5)),\"k\",linewidth = 3)\n",
    "\n",
    "#ax.fill_between([0,4], [p(0)-inter_err , p(4) - 4 * slope_err - inter_err], [p(0)+inter_err , p(4) + 4 * slope_err + inter_err], color='k', alpha=.1)\n",
    "\n",
    "\n",
    "\n",
    "ax.minorticks_on()\n",
    "ax.tick_params('both', length=10, width=2, which='major',direction=\"in\")\n",
    "ax.tick_params('both', length=5, width=1, which='minor',direction=\"in\")\n",
    "ax.tick_params(axis='x', labelsize=35)\n",
    "ax.tick_params(axis='y', labelsize=35)\n",
    "ax.set_aspect(1)\n",
    "plt.xlim([-0.15, 4])\n",
    "plt.ylim([-0.3, 4])\n",
    "plt.xlabel(r'$BARS^{clin}_{speech}$', fontsize=40)\n",
    "plt.ylabel(r'$BARS^{pred}_{speech}$', fontsize=40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3d4c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee0d800",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(val_demo_bars['BARS_obsr'], val_demo_bars['BARS_pred'],squared = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d405c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(val_demo_bars['BARS_obsr'], val_demo_bars['BARS_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7448f54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(val_demo_bars['BARS_obsr'], val_demo_bars['BARS_pred'], multioutput='variance_weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc95c224",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "val_demo_bars = val_demo_all[['P_ID','Sex','Label', 'Age','BARS_obsr', 'BARS_pred','Date']]\n",
    "#val_demo_bars = val_demo_bars[val_demo_bars['BARS_obsr'].notna()]\n",
    "#val_demo_bars = val_demo_bars[val_demo_bars['BARS_obsr'] >= 0]\n",
    "val_demo_bars = val_demo_bars[val_demo_bars['Label'] == 1]\n",
    "val_demo_bars_male = val_demo_bars[val_demo_bars['Sex'] == \"M\"]\n",
    "val_demo_bars_female = val_demo_bars[val_demo_bars['Sex'] == \"F\"]\n",
    "val_demo_bars_male[\"ID_ranked\"] = val_demo_bars_male[\"P_ID\"]#.rank()-1\n",
    "val_demo_bars_female[\"ID_ranked\"] = val_demo_bars_female[\"P_ID\"]#.rank()-1\n",
    "val_demo_bars = val_demo_bars[['P_ID','Label', 'Age','BARS_obsr', 'BARS_pred', 'Date']].astype('float64')\n",
    "val_demo_bars = val_demo_bars.groupby(['Date'], as_index = False).median()\n",
    "\n",
    "\n",
    "val_demo_bars_male = val_demo_bars_male[['ID_ranked','Label', 'Age','BARS_obsr', 'BARS_pred','Date']]\n",
    "val_demo_bars_male = val_demo_bars_male.astype('float64')\n",
    "\n",
    "val_demo_bars_female = val_demo_bars_female[['ID_ranked','Label', 'Age','BARS_obsr', 'BARS_pred','Date']]\n",
    "val_demo_bars_female = val_demo_bars_female.astype('float64')\n",
    "\n",
    "\n",
    "val_demo_bars_male = val_demo_bars_male.groupby(['Date'], as_index = False).median()\n",
    "val_demo_bars_female = val_demo_bars_female.groupby(['Date'], as_index = False).median()\n",
    "\n",
    "\n",
    "male_month_diff_1 = []\n",
    "male_month_diff_2 = []\n",
    "male_month_diff_3 = []\n",
    "male_month_diff_4 = []\n",
    "male_bars_diff_1 = []\n",
    "male_bars_diff_2 = []\n",
    "male_bars_diff_3 = []\n",
    "male_bars_diff_4 = []\n",
    "male_init_bars = []\n",
    "female_month_diff_1 = []\n",
    "female_month_diff_2 = []\n",
    "female_month_diff_3 = []\n",
    "female_month_diff_4 = []\n",
    "female_bars_diff_1 = []\n",
    "female_bars_diff_2 = []\n",
    "female_bars_diff_3 = []\n",
    "female_bars_diff_4 = []\n",
    "female_init_bars = []\n",
    "\n",
    "#print(val_demo_bars_male['Date'].astype(str).str[5:9].astype(float)*12. + val_demo_bars_male['Date'].astype(str).str[9:11].astype(float))\n",
    "for vv in val_demo_bars_male['ID_ranked'].unique():\n",
    "    if val_demo_bars_male['ID_ranked'].value_counts().loc[vv] > 1:\n",
    "        val_demo_bars_male_lines = val_demo_bars_male[val_demo_bars_male['ID_ranked'] == vv]\n",
    "        val_demo_bars_male_lines = val_demo_bars_male_lines.sort_values(by=['Date'])\n",
    "        val_demo_bars_male_lines['Months'] = val_demo_bars_male_lines['Date'].astype(str).str[5:9].astype(float)*12. + val_demo_bars_male_lines['Date'].astype(str).str[9:11].astype(float)\n",
    "        month_diff = val_demo_bars_male_lines['Months'].iloc[-1]- val_demo_bars_male_lines['Months'].iloc[0]\n",
    "        if month_diff > 1:\n",
    "            male_init_bars.append(val_demo_bars_male_lines['BARS_obsr'].iloc[0])\n",
    "            Bars_pred_diff = val_demo_bars_male_lines['BARS_pred'].iloc[-1]- val_demo_bars_male_lines['BARS_pred'].iloc[0]\n",
    "            Bars_obs_diff = val_demo_bars_male_lines['BARS_obsr'].iloc[-1]- val_demo_bars_male_lines['BARS_obsr'].iloc[0]\n",
    "            if Bars_obs_diff == 0.:\n",
    "                male_bars_diff_1.append(Bars_pred_diff)\n",
    "                male_month_diff_1.append(month_diff)\n",
    "            elif ((Bars_obs_diff > 0.0) and (Bars_obs_diff < 0.75)):\n",
    "                male_bars_diff_2.append(Bars_pred_diff)\n",
    "                male_month_diff_2.append(month_diff)\n",
    "            else:\n",
    "                male_bars_diff_3.append(Bars_pred_diff)\n",
    "                male_month_diff_3.append(month_diff)\n",
    "            if Bars_pred_diff < 0:\n",
    "                print(vv)\n",
    "            \n",
    "for vv in val_demo_bars_female['ID_ranked'].unique():\n",
    "    if val_demo_bars_female['ID_ranked'].value_counts().loc[vv] > 1:\n",
    "        val_demo_bars_female_lines = val_demo_bars_female[val_demo_bars_female['ID_ranked'] == vv]\n",
    "        val_demo_bars_female_lines = val_demo_bars_female_lines.sort_values(by=['Date'])\n",
    "        val_demo_bars_female_lines['Months'] = val_demo_bars_female_lines['Date'].astype(str).str[5:9].astype(float)*12. + val_demo_bars_female_lines['Date'].astype(str).str[9:11].astype(float)\n",
    "        month_diff = val_demo_bars_female_lines['Months'].iloc[-1]- val_demo_bars_female_lines['Months'].iloc[0]\n",
    "        if month_diff > 1:\n",
    "            female_init_bars.append(val_demo_bars_female_lines['BARS_obsr'].iloc[0])\n",
    "            Bars_pred_diff = val_demo_bars_female_lines['BARS_pred'].iloc[-1]- val_demo_bars_female_lines['BARS_pred'].iloc[0]\n",
    "            Bars_obs_diff = val_demo_bars_female_lines['BARS_obsr'].iloc[-1]- val_demo_bars_female_lines['BARS_obsr'].iloc[0]\n",
    "            if Bars_obs_diff == 0:\n",
    "                female_bars_diff_1.append(Bars_pred_diff)\n",
    "                female_month_diff_1.append(month_diff)\n",
    "            elif ((Bars_obs_diff > 0) and (Bars_obs_diff < 0.50)):\n",
    "                female_bars_diff_2.append(Bars_pred_diff)\n",
    "                female_month_diff_2.append(month_diff)\n",
    "            else:\n",
    "                female_bars_diff_3.append(Bars_pred_diff)\n",
    "                female_month_diff_3.append(month_diff)\n",
    "            if Bars_pred_diff < 0:\n",
    "                print(vv)\n",
    "                \n",
    "ax.scatter(male_month_diff_1, male_bars_diff_1, c = 'red', marker = 'o',s = 90)#10*np.array(male_init_bars))\n",
    "ax.scatter(male_month_diff_2, male_bars_diff_2, c = 'red', marker = 'o',s = 90)#10*np.array(male_init_bars))\n",
    "ax.scatter(male_month_diff_3, male_bars_diff_3, c = 'red', marker = 'o',s = 90)#10*np.array(male_init_bars))\n",
    "#ax.scatter(male_month_diff_4, male_bars_diff_4, c = 'orange', marker = 'o',s = 70)#10*np.array(male_init_bars))\n",
    "\n",
    "ax.scatter(female_month_diff_1, female_bars_diff_1, c = 'red', marker = 'o',s = 90)#10*np.array(male_init_bars))\n",
    "ax.scatter(female_month_diff_2, female_bars_diff_2, c = 'red', marker = 'o',s = 90)#10*np.array(male_init_bars))\n",
    "ax.scatter(female_month_diff_3, female_bars_diff_3, c = 'red', marker = 'o',s = 90)#10*np.array(male_init_bars))\n",
    "#ax.scatter(female_month_diff_4, female_bars_diff_4, c = 'orange', marker = 'x',s = 70)#10*np.array(male_init_bars))\n",
    "\n",
    "print(np.mean(male_bars_diff_1 + male_bars_diff_2 + male_bars_diff_3 + female_bars_diff_1 + female_bars_diff_2 + female_bars_diff_3 ), np.std(male_bars_diff_1 + male_bars_diff_2 + male_bars_diff_3 + female_bars_diff_1 + female_bars_diff_2 + female_bars_diff_3 ))\n",
    "\n",
    "ax.scatter([], [], c = 'red', marker = 'o',s = 90, label=r'$\\rm{\\Delta BARS^{clin}_{speech}} = 0$')#10*np.array(male_init_bars))\n",
    "ax.scatter([], [], c = 'red', marker = 'o',s = 90, label=r'$0 < \\rm{\\Delta BARS^{clin}_{speech}} < 0.75$')#10*np.array(male_init_bars))\n",
    "ax.scatter([], [], c = 'red', marker = 'o',s = 90, label=r'$\\rm{\\Delta BARS^{clin}_{speech}}$ > 0.75')#10*np.array(male_init_bars))\n",
    "#plt.legend(fontsize=25,loc = 'lower right')\n",
    "ax.minorticks_on()\n",
    "ax.tick_params('both', length=10, width=2, which='major',direction=\"in\")\n",
    "ax.tick_params('both', length=5, width=1, which='minor',direction=\"in\")\n",
    "\n",
    "plt.axhline(y=0., color='k', linestyle='--')\n",
    "#plt.axhline(y=0.75, color='k', linestyle='--')\n",
    "ax.tick_params(axis='x', labelsize=35)\n",
    "ax.tick_params(axis='y', labelsize=35)\n",
    "ax.set_aspect(45.2/3.)\n",
    "plt.xlim([-0.2, 45])\n",
    "plt.ylim([-1.5, 1.5])\n",
    "plt.xlabel(r'$\\rm{Months}$', fontsize=40)\n",
    "plt.ylabel(r'$\\rm{\\Delta BARS^{pred}_{speech}}$', fontsize=40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0b14df",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_diff =  male_month_diff_1 + male_month_diff_2 + male_month_diff_3 + female_month_diff_1 + female_month_diff_2 + female_month_diff_3 \n",
    "bars_diff = male_bars_diff_1 + male_bars_diff_2 + male_bars_diff_3  + female_bars_diff_1 + female_bars_diff_2 + female_bars_diff_3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ef42ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.spearmanr( month_diff, bars_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90f3a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_1samp(bars_diff, 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4c563b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628e741f",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_demo_bars = val_demo_all[['P_ID','Sex','Label', 'Age','BARS_obsr', 'BARS_pred','Date']]\n",
    "#val_demo_bars = val_demo_bars[val_demo_bars['BARS_obsr'].notna()]\n",
    "#val_demo_bars = val_demo_bars[val_demo_bars['BARS_obsr'] >= 0]\n",
    "#val_demo_bars = val_demo_bars[val_demo_bars['Label'] == 1]\n",
    "val_demo_bars_male = val_demo_bars[val_demo_bars['Sex'] == \"M\"]\n",
    "val_demo_bars_female = val_demo_bars[val_demo_bars['Sex'] == \"F\"]\n",
    "val_demo_bars_male[\"ID_ranked\"] = val_demo_bars_male[\"P_ID\"]#.rank()-1\n",
    "val_demo_bars_female[\"ID_ranked\"] = val_demo_bars_female[\"P_ID\"]#.rank()-1\n",
    "val_demo_bars = val_demo_bars[['P_ID','Label', 'Age','BARS_obsr', 'BARS_pred', 'Date']].astype('float64')\n",
    "val_demo_bars = val_demo_bars.groupby(['Date'], as_index = False).median()\n",
    "\n",
    "\n",
    "val_demo_bars_male = val_demo_bars_male[['ID_ranked','Label', 'Age','BARS_obsr', 'BARS_pred','Date']]\n",
    "val_demo_bars_male = val_demo_bars_male.astype('float64')\n",
    "\n",
    "val_demo_bars_female = val_demo_bars_female[['ID_ranked','Label', 'Age','BARS_obsr', 'BARS_pred','Date']]\n",
    "val_demo_bars_female = val_demo_bars_female.astype('float64')\n",
    "\n",
    "\n",
    "val_demo_bars_male = val_demo_bars_male.groupby(['Date'], as_index = False).median()\n",
    "val_demo_bars_female = val_demo_bars_female.groupby(['Date'], as_index = False).median()\n",
    "\n",
    "val_demo_bars_male['MAE'] = np.abs(val_demo_bars_male['BARS_obsr'] - val_demo_bars_male['BARS_pred'])\n",
    "val_demo_bars_female['MAE'] = np.abs(val_demo_bars_female['BARS_obsr'] - val_demo_bars_female['BARS_pred'])\n",
    "\n",
    "val_demo_bars_male_np_control = val_demo_bars_male[(val_demo_bars_male['Label'] == 0) ]['MAE'].to_numpy()\n",
    "val_demo_bars_female_np_control = val_demo_bars_female[(val_demo_bars_female['Label'] == 0)]['MAE'].to_numpy()\n",
    "\n",
    "val_demo_bars_male_np_ataxia = val_demo_bars_male[(val_demo_bars_male['Label'] == 1) ]['MAE'].to_numpy()\n",
    "val_demo_bars_female_np_ataxia = val_demo_bars_female[(val_demo_bars_female['Label'] == 1)]['MAE'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10cbb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_ind(a=val_demo_bars_male_np_control, b=val_demo_bars_female_np_control, equal_var=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb4e07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_ind(a=val_demo_bars_male_np_ataxia, b=val_demo_bars_female_np_ataxia, equal_var=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871af58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_demo_bars = val_demo_all[['P_ID','Sex','Label', 'Age','BARS_obsr', 'BARS_pred','Date']]\n",
    "#val_demo_bars = val_demo_bars[val_demo_bars['BARS_obsr'].notna()]\n",
    "#val_demo_bars = val_demo_bars[val_demo_bars['BARS_obsr'] >= 0]\n",
    "#val_demo_bars = val_demo_bars[val_demo_bars['Label'] == 1]\n",
    "val_demo_bars['MAE'] = np.abs(val_demo_bars['BARS_obsr'] - val_demo_bars['BARS_pred'])\n",
    "#val_demo_bars.loc[(val_demo_bars.Label == 0),'Bars']= 0.\n",
    "val_demo_bars.loc[(val_demo_bars.Sex == 'M'),'Sex']= 0\n",
    "val_demo_bars.loc[(val_demo_bars.Sex == 'F'),'Sex']= 1\n",
    "val_demo_bars[\"ID_ranked\"] = val_demo_bars[\"P_ID\"].rank()-1\n",
    "val_demo_bars = val_demo_bars.astype('float64')\n",
    "val_demo_bars = val_demo_bars.groupby(['Date',\"Age\"], as_index = False).median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b75138f",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_demo_bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4431e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_demo_bars[['MAE','Age']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b941efd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.spearmanr(val_demo_bars['Age'], val_demo_bars['MAE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea0fa2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff384d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_demo_bars = val_demo_all[['P_ID','Sex','Label', 'Age','BARS_obsr', 'BARS_pred','Date']]\n",
    "#val_demo_bars.loc[(val_demo_bars.Label == 0),'BARS_obsr']= 0.\n",
    "#val_demo_bars = val_demo_bars[val_demo_bars['BARS_obsr'].notna()]\n",
    "#val_demo_bars = val_demo_bars[val_demo_bars['BARS_obsr'] >= 0]\n",
    "val_demo_bars = val_demo_bars[val_demo_bars['Label'] == 1]\n",
    "val_demo_bars['MAE'] = np.abs(val_demo_bars['BARS_obsr'] - val_demo_bars['BARS_pred'])\n",
    "val_demo_bars.loc[(val_demo_bars.Sex == 'M'),'Sex']= 0\n",
    "val_demo_bars.loc[(val_demo_bars.Sex == 'F'),'Sex']= 1\n",
    "val_demo_bars[\"ID_ranked\"] = val_demo_bars[\"P_ID\"].rank()-1\n",
    "val_demo_bars = val_demo_bars.astype('float64')\n",
    "val_demo_bars = val_demo_bars.groupby(['Date',\"Age\"], as_index = False).median()\n",
    "\n",
    "val_demo_bars_0 = val_demo_bars[val_demo_bars['BARS_obsr'] == 0]\n",
    "val_demo_bars_05 = val_demo_bars[val_demo_bars['BARS_obsr'] == 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50467d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val_demo_bars_05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5b0692",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_ind(a=val_demo_bars_0['BARS_pred'], b=val_demo_bars_05['BARS_pred'], equal_var=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f8f952",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(val_demo_bars_0['BARS_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6b5290",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(val_demo_bars_05['BARS_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01eebd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.mannwhitneyu(val_demo_bars_0['BARS_pred'],val_demo_bars_05['BARS_pred'],alternative = 'less')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb2ab1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(val_demo_bars_0['BARS_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73bedd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(val_demo_bars_05['BARS_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acbebc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_demo_bars = val_demo_all[['P_ID','Sex','Label', 'Age','BARS_obsr', 'BARS_pred','Date']]\n",
    "#val_demo_bars = val_demo_bars[val_demo_bars['Label'] == 1]\n",
    "val_demo_bars['MAE'] = np.abs(val_demo_bars['BARS_obsr'] - val_demo_bars['BARS_pred'])\n",
    "val_demo_bars.loc[(val_demo_bars.Sex == 'M'),'Sex']= 0\n",
    "val_demo_bars.loc[(val_demo_bars.Sex == 'F'),'Sex']= 1\n",
    "val_demo_bars[\"ID_ranked\"] = val_demo_bars[\"P_ID\"].rank()-1\n",
    "val_demo_bars = val_demo_bars.astype('float64')\n",
    "val_demo_bars = val_demo_bars.groupby(['Date',\"Age\"], as_index = False).median()\n",
    "\n",
    "val_demo_bars_0 = val_demo_bars[val_demo_bars['BARS_obsr'] == 0]\n",
    "val_demo_bars_05 = val_demo_bars[val_demo_bars['BARS_obsr'] == 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd19b849",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val_demo_bars_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bc7a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_ind(a=val_demo_bars_0[val_demo_bars_0['Label'] == 0]['BARS_pred'], b=val_demo_bars_0[val_demo_bars_0['Label'] == 1]['BARS_pred'], equal_var=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff84cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.mannwhitneyu(val_demo_bars_0[val_demo_bars_0['Label'] == 0]['BARS_pred'],val_demo_bars_0[val_demo_bars_0['Label'] == 1]['BARS_pred'],alternative = 'less')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c655e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(val_demo_bars_0[val_demo_bars_0['Label'] == 0]['BARS_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c595396a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(val_demo_bars_0[val_demo_bars_0['Label'] == 1]['BARS_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79df0454",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/kvattis/Desktop/bars_pred_dist.npy', 'rb') as f:\n",
    "    bars_pred_controls = np.load(f)\n",
    "    bars_pred_ataxia0 = np.load(f)\n",
    "    bars_pred_ataxia05 = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe679bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxprops = dict(linestyle='-', linewidth=4, color='k')\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "h1 = ax.boxplot([val_demo_bars_0[val_demo_bars_0['Label'] == 0]['BARS_pred'],val_demo_bars_0[val_demo_bars_0['Label'] == 1]['BARS_pred'], val_demo_bars_05['BARS_pred']],\n",
    "             positions = [2,5,8],\n",
    "             boxprops=dict(linestyle='-', linewidth=4),\n",
    "             flierprops=dict( linewidth=4),\n",
    "             medianprops=dict(linestyle='-', linewidth=4,color='red'),\n",
    "             whiskerprops=dict(linestyle='-', linewidth=4),\n",
    "             capprops=dict(linestyle='-', linewidth=4))\n",
    "\n",
    "h2 = ax.boxplot([bars_pred_controls,bars_pred_ataxia0, bars_pred_ataxia05],\n",
    "             positions = [1,4,7],\n",
    "             boxprops=dict(linestyle='--', linewidth=4),\n",
    "             flierprops=dict( linewidth=4),\n",
    "             medianprops=dict(linestyle='-', linewidth=4,color='red'),\n",
    "             whiskerprops=dict(linestyle='--', linewidth=4),\n",
    "             capprops=dict(linestyle='-', linewidth=4))\n",
    "\n",
    "ax.legend([h2[\"boxes\"][0], h1[\"boxes\"][0]], [\"Time\",\"Time and Frequency\"], loc=(5.5e-1,1.5e-1),fontsize = 18)\n",
    "\n",
    "#plt.axhline(y=0.5, color='blue', linestyle='-',linewidth=4)\n",
    "plt.tick_params(axis='y', which='minor')\n",
    "ax.tick_params(axis='x', labelsize=35)\n",
    "ax.tick_params(axis='y', labelsize=35)\n",
    "ax.set_xticks([1.5,4.5,7.5])\n",
    "ax.set_xticklabels([r'$\\rm{Controls}$',r'$\\rm{Ataxia}$',r'$\\rm{Ataxia}$'])\n",
    "plt.text(3.1, 1e-4, r'$BARS^{clin}_{speech} = 0$', fontsize=23)\n",
    "plt.text(5.95, 1e-4, r'$BARS^{clin}_{speech} = 0.5$', fontsize=23)\n",
    "plt.ylabel(r'$BARS^{pred}_{speech}$', fontsize=40)\n",
    "ax.set_aspect(1.65)\n",
    "ax.yaxis.grid(True, which='major')\n",
    "ax.yaxis.grid(True, which='minor',alpha =0.4)\n",
    "plt.ylim([6e-5, 4])\n",
    "plt.xlim([6e-5, 9])\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5900d79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxprops = dict(linestyle='-', linewidth=4, color='k')\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "h1 = ax.boxplot([val_demo_bars_0[val_demo_bars_0['Label'] == 0]['BARS_pred'],val_demo_bars_0[val_demo_bars_0['Label'] == 1]['BARS_pred'], val_demo_bars_05['BARS_pred']],\n",
    "             positions = [2,5,8],\n",
    "             boxprops=dict(linestyle='-', linewidth=4),\n",
    "             flierprops=dict( linewidth=4),\n",
    "             medianprops=dict(linestyle='-', linewidth=4,color='red'),\n",
    "             whiskerprops=dict(linestyle='-', linewidth=4),\n",
    "             capprops=dict(linestyle='-', linewidth=4))\n",
    "\n",
    "h2 = ax.boxplot([bars_pred_controls,bars_pred_ataxia0, bars_pred_ataxia05],\n",
    "             positions = [1,4,7],\n",
    "             boxprops=dict(linestyle='--', linewidth=4),\n",
    "             flierprops=dict( linewidth=4),\n",
    "             medianprops=dict(linestyle='-', linewidth=4,color='red'),\n",
    "             whiskerprops=dict(linestyle='--', linewidth=4),\n",
    "             capprops=dict(linestyle='-', linewidth=4))\n",
    "\n",
    "ax.legend([h2[\"boxes\"][0], h1[\"boxes\"][0]], [\"Time\",\"Time and Frequency\"], loc=(5.5e-1,8e-1),fontsize = 18)\n",
    "\n",
    "#plt.axhline(y=0.5, color='blue', linestyle='-',linewidth=4)\n",
    "plt.tick_params(axis='y', which='minor')\n",
    "ax.tick_params(axis='x', labelsize=35)\n",
    "ax.tick_params(axis='y', labelsize=35)\n",
    "ax.set_xticks([1.5,4.5,7.5])\n",
    "ax.set_xticklabels([r'$\\rm{Controls}$',r'$\\rm{Ataxia}$',r'$\\rm{Ataxia}$'])\n",
    "plt.text(3.1, -0.35, r'$BARS^{clin}_{speech} = 0$', fontsize=23)\n",
    "plt.text(5.95, -0.35, r'$BARS^{clin}_{speech} = 0.5$', fontsize=23)\n",
    "plt.ylabel(r'$BARS^{pred}_{speech}$', fontsize=40)\n",
    "ax.set_aspect(3)\n",
    "ax.yaxis.grid(True, which='major')\n",
    "ax.yaxis.grid(True, which='minor',alpha =0.4)\n",
    "plt.ylim([0, 2.5])\n",
    "plt.xlim([6e-5, 9])\n",
    "#plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee0fd1d",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2680a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels = trained_model_v0.model.C1.weight.data\n",
    "for i in range(kernels.shape[0]):\n",
    "    fig = plt.figure()\n",
    "    ax1 = fig.add_subplot(1, 1, 1)\n",
    "    ax1.imshow((kernels.numpy()[i][0] - np.mean(kernels.numpy()[i][0]))/np.std(kernels.numpy()[i][0]))\n",
    "    ax1.axis('off')\n",
    "    ax1.set_xticklabels([])\n",
    "    ax1.set_yticklabels([])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99231ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_demo_bars = val_demo_all[['P_ID','Date','Bars','Bars_Speech','BARS_pred','Sex','Label', 'Age']]\n",
    "val_demo_bars.loc[(val_demo_bars.Label == 0),'Bars']= 0\n",
    "val_demo_bars.loc[(val_demo_bars.Label == 0),'Bars_Speech']= 0\n",
    "val_demo_bars.loc[(val_demo_bars.Sex == 'M'),'Sex'] = 0\n",
    "val_demo_bars.loc[(val_demo_bars.Sex == 'F'),'Sex'] = 1\n",
    "\n",
    "val_demo_bars = val_demo_bars.astype('float64')\n",
    "\n",
    "val_demo_bars = val_demo_bars.groupby(['Date'], as_index = False).median()\n",
    "val_demo_bars.loc[(val_demo_bars['P_ID'] == 10251) & (val_demo_bars['Date'] >= 1025120201116),'P_ID'] = 30001\n",
    "val_demo_bars.loc[(val_demo_bars['P_ID'] == 10094) & (val_demo_bars['Date'] >= 1009420210115),'P_ID'] = 30004\n",
    "val_demo_bars.loc[(val_demo_bars['P_ID'] == 10068) & (val_demo_bars['Date'] >= 1006820210326),'P_ID'] = 30007\n",
    "val_demo_bars.loc[(val_demo_bars['P_ID'] == 10245) & (val_demo_bars['Date'] >= 1024520210723),'P_ID'] = 30007\n",
    "val_demo_bars['Date'] = val_demo_bars['Date'].astype(str).str.slice(5,13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ac9357",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('float_format', '{:f}'.format):\n",
    "    print(val_demo_bars[(val_demo_bars['P_ID']>30000)]['P_ID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215cf44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('float_format', '{:f}'.format):\n",
    "    print(val_demo_bars[(val_demo_bars['P_ID']>30000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a8c1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_demo_bars[(val_demo_bars['P_ID']>30000)].to_pickle('/home/kvattis/Desktop/tf_bars_speech.pd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83efd3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.scatter(val_demo_bars[(val_demo_bars['P_ID']>30000)]['Bars_Speech'], val_demo_bars[(val_demo_bars['P_ID']>30000)]['BARS_pred'], c = val_demo_bars[(val_demo_bars['P_ID']>30000)]['Label'],cmap=\"bwr\", marker = 'o', s = 2*val_demo_bars[(val_demo_bars['P_ID']>30000)]['Age'])\n",
    "ax.plot([0, 4], [0, 4],color = 'k',linewidth = 5,linestyle ='-.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7e21a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ea6825",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009629fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d198a710",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297f6b56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b520d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739b5cf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0358b885",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
