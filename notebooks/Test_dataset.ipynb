{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1684d5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "sys.path.append('../../')\n",
    "\n",
    "from script.Model_run import Speech_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee3fbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Directory where the data are stored\n",
    "data_home_dir = '/home/kvattis/Dropbox (Partners HealthCare)/Data_Raw_Biogen_SCA/'\n",
    "data_home_dir_at = '/home/kvattis/Dropbox (Partners HealthCare)/Data_Raw_A-T_Remote_Study/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4145bf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_analyzer = Speech_analysis(print_on = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c44207",
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_analyzer.class_map[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ca8649",
   "metadata": {},
   "outputs": [],
   "source": [
    "IDs_used = list({x for l in speech_analyzer.class_map for x in l})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e352bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(IDs_used)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2b17d8",
   "metadata": {},
   "source": [
    "# Biogen SCA study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdf49b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#survey_lex = pd.read_csv(data_home_dir + 'Biogen_SCA_Speech_Data/' + 'surveylex_questionIDs.csv',encoding='latin1')\n",
    "survey_lex = pd.read_excel(data_home_dir + 'Biogen_SCA_Speech_Data/' + 'surveylex_questionIDs.xlsx',engine='openpyxl')\n",
    "taskslist = survey_lex['question'].unique()\n",
    "output = pd.DataFrame(columns = ['Date','subject_id','Neuropheno_ID','Bars','Bars_Speech','Sex','Diagnosis','DoB','Samples_no','Prob_AT_tf_grad', 'Bars_Speech_pred_t','Bars_Total_pred_t'])\n",
    "                      \n",
    "for tt in  taskslist: \n",
    "    if tt not in [\"la_la_la\",\"go_go_go\",\"me_me_me\", \"lalala\", \"gogogo\", \"mememe\",\"papapa\"]:\n",
    "        continue\n",
    "    print(tt)\n",
    "    pd.set_option('display.max_columns', 4)\n",
    "    np.dtype(np.int16)\n",
    "    task = str(tt)\n",
    "    task_dir = str(tt)\n",
    "    \n",
    "    study_name = 'Biogen_SCA_Speech_Data'\n",
    "    study_dir = data_home_dir + 'Biogen_SCA_Speech_Data/'\n",
    "    #survey_lex = pd.read_csv(study_dir + 'surveylex_questionIDs.csv',encoding='latin1')\n",
    "    survey_lex = pd.read_excel(study_dir + 'surveylex_questionIDs.xlsx',engine='openpyxl')\n",
    "\n",
    "    survey_response_A = pd.read_excel(study_dir + 'surveyA-responses-summary_.xlsx',engine='openpyxl')\n",
    "    survey_response_B = pd.read_excel(study_dir + 'surveyB-responses-summary_.xlsx',engine='openpyxl')\n",
    "    survey_response_C = pd.read_excel(study_dir + 'surveyC-responses-summary_.xlsx',engine='openpyxl')\n",
    "    survey_response_D = pd.read_excel(study_dir + 'surveyD-responses-summary_.xlsx',engine='openpyxl')\n",
    "    \n",
    "    survey_response = pd.concat([survey_response_A, survey_response_B, survey_response_C, survey_response_D], ignore_index=True)\n",
    "\n",
    "    survey_submissions_A = pd.read_excel(study_dir + 'surveyA-submissions-summary_.xlsx',engine='openpyxl')\n",
    "    survey_submissions_B = pd.read_excel(study_dir + 'surveyB-submissions-summary_.xlsx',engine='openpyxl')\n",
    "    survey_submissions_C = pd.read_excel(study_dir + 'surveyC-submissions-summary_.xlsx',engine='openpyxl')\n",
    "    survey_submissions_D = pd.read_excel(study_dir + 'surveyD-submissions-summary_.xlsx',engine='openpyxl')\n",
    "    \n",
    "\n",
    "    survey_submissions = pd.concat([survey_submissions_A, survey_submissions_B, survey_submissions_C, survey_submissions_D], ignore_index=True)\n",
    "\n",
    "    #Patient_info = pd.read_csv(study_dir + 'Subjects_BiogenSCA_version2.csv',encoding='latin1')\n",
    "    #Patient_info = pd.read_csv(data_home_dir + 'Subjects_BiogenSCA_version2.csv',encoding='latin1')\n",
    "    #Patient_info_ = Patient_info.loc[:,['subject_id','neuropheno_id','diagnosis','bars_total_excl_miss_1','bars_total_excl_miss_2', 'bars_speech_1', 'bars_speech_2','sex', 'age']]\n",
    "    \n",
    "    _Patient_info = pd.read_csv(data_home_dir + 'Subjects/Subjects_BiogenSCA_version2.csv',encoding='latin1')\n",
    "    _Patient_info_ = _Patient_info.loc[:,['subject_id','neuropheno_id','diagnosis','bars_total_excl_miss_1','bars_total_excl_miss_2', 'bars_speech_1', 'bars_speech_2','sex']]\n",
    "\n",
    "    Patient_info = pd.read_excel(data_home_dir + 'Subjects/Subjects_BiogenSCA_with_questionnaires_2022_05_04_converted.xlsx',engine='openpyxl')\n",
    "    Patient_info_ = Patient_info.loc[:,['subject_id','neuropheno_id','diagnosis','bars_total_excl_miss_1','bars_total_excl_miss_2', 'bars_speech_1', 'bars_speech_2','sex','dob']]\n",
    "    \n",
    "    for i in _Patient_info_['subject_id']:\n",
    "        Patient_info_.loc[Patient_info_['subject_id'] == i,'neuropheno_id']  = _Patient_info_.loc[_Patient_info_['subject_id'] == i,'neuropheno_id']\n",
    "    \n",
    "    survey_lex_ = survey_lex.loc[:,['questionId','question']]\n",
    "    survey_response_ = survey_response.loc[:,['sampleId','questionId', 'sessionId','createdDate']]\n",
    "    survey_response_['createdDate'] = survey_response_['createdDate'].apply(lambda x: x[0:4] + '_' + x[5:7] + '_' + x[8:10] )\n",
    "    survey_submissions_ = survey_submissions.loc[:,['sessionId','Your participant ID:']]\n",
    "    survey_submissions_ = survey_submissions_.rename(columns={\"Your participant ID:\": \"subject_id\"})\n",
    "    df = pd.merge(pd.merge(pd.merge(survey_response_,survey_lex_,on='questionId'), survey_submissions_, on = 'sessionId'),Patient_info_, on = 'subject_id')\n",
    "    df.dropna(subset = [\"sampleId\"], inplace=True)\n",
    "\n",
    "    df_task = df.loc[df['question'] == task][['sampleId','subject_id','neuropheno_id','diagnosis','createdDate','bars_total_excl_miss_1','bars_total_excl_miss_2', 'bars_speech_1', 'bars_speech_2','sex']]#, 'age']]\n",
    "    df_task_numpy = df_task.to_numpy()\n",
    "\n",
    "    \n",
    "        \n",
    "    list_diagnostic = ['Control', 'Ataxia', 'MSA', 'Other']\n",
    "\n",
    "    \n",
    "    #Going over all the files for the task\n",
    "    list_names = []\n",
    "    for entry in df_task_numpy:\n",
    "        file_name = entry[0]\n",
    "        ID = str(entry[1])\n",
    "\n",
    "        if  not np.isnan(entry[2]):\n",
    "            Neur_phen_id = str(int(entry[2]))\n",
    "        else:\n",
    "            Neur_phen_id = ID\n",
    "            \n",
    "        if int(Neur_phen_id) in IDs_used:\n",
    "            continue\n",
    "        \n",
    "        diagn = entry[3]\n",
    "        date = entry[4]\n",
    "        Date = date[:4] + date[5:7] + date[8:]\n",
    "        bars_total = (entry[5] + entry[6])/2.\n",
    "        bars_speech = (entry[7] + entry[8])/2./10.\n",
    "        sex = entry[9]\n",
    "        #age = entry[10]\n",
    "        \n",
    "        path_to_file = study_dir + ID + '_' + date + '_A/' + file_name + '.wav'\n",
    "        path_to_file_flag = 0\n",
    "        \n",
    "        if os.path.exists(path_to_file):\n",
    "            path_to_file_flag = 1 \n",
    "        \n",
    "        if not os.path.exists(path_to_file):\n",
    "            path_to_file = study_dir + ID + '_' + date + '_B/' + file_name + '.wav'\n",
    "        else:\n",
    "            path_to_file_flag = 1\n",
    "        \n",
    "        if not os.path.exists(path_to_file):\n",
    "            path_to_file = study_dir + ID + '_' + date + '_C/' + file_name + '.wav'\n",
    "        else:\n",
    "            path_to_file_flag = 1\n",
    "            \n",
    "        if not os.path.exists(path_to_file):\n",
    "            path_to_file = study_dir + ID + '_' + date + '_D/' + file_name + '.wav'\n",
    "        else:\n",
    "            path_to_file_flag = 1    \n",
    "            \n",
    "        if path_to_file_flag == 0: continue;\n",
    "            \n",
    "        #Assign label\n",
    "        if diagn == 0:\n",
    "            #diagn = 'Control'\n",
    "            label = 0\n",
    "        elif diagn == 1:\n",
    "            #diagn = 'Ataxia'\n",
    "            label = 1\n",
    "        elif diagn == 2:\n",
    "            #diagn = 'Ataxia'\n",
    "            label = 1\n",
    "        elif diagn == 3:\n",
    "            #diagn = 'Ataxia'\n",
    "            label = 1\n",
    "        elif diagn == 7:\n",
    "            #diagn = 'MSA'\n",
    "            label = 7\n",
    "        else:\n",
    "            #diagn = 'Other'\n",
    "            label = 5\n",
    "        \n",
    "        if label not in [0,1]:\n",
    "            continue\n",
    "        \n",
    "        if label == 0:\n",
    "            bars_total = 0\n",
    "            bars_speech = 0 \n",
    "        \n",
    "        if Neur_phen_id == ID:\n",
    "            #print(path_to_file)\n",
    "            no_samples = speech_analyzer.load(path_to_file)\n",
    "            Neur_phen_id = None\n",
    "        else:\n",
    "            no_samples = speech_analyzer.load(path_to_file,Neur_phen_id)\n",
    "        \n",
    "        if no_samples == 0: \n",
    "            continue\n",
    "            \n",
    "        output = output.append({'Date' : Date, 'subject_id' : ID, 'Neuropheno_ID' : Neur_phen_id, 'Bars': bars_total, 'Bars_Speech':bars_speech, 'Sex': sex, 'Diagnosis': diagn,'Samples_no' : speech_analyzer.sample_size_s, 'Prob_AT_tf_grad': speech_analyzer.classify(),\n",
    "                               'Bars_Speech_pred_t': speech_analyzer.BARS_speech(), 'Bars_Total_pred_t': speech_analyzer.BARS_total()}, \n",
    "                ignore_index = True)\n",
    "        \n",
    "output = output.astype(float).groupby(['Date','subject_id'], as_index = False).median().sort_values(by=['subject_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9661e27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_analyzer.plot_wav()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774218b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_analyzer.play_audio_nr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac32ac34",
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_analyzer.plot_mel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b92573",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 10)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "np.dtype(np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f303f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a430ad51",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in output['subject_id'].unique():\n",
    "    output.loc[output['subject_id'] == i,'DoB'] = pd.to_datetime(Patient_info_.loc[Patient_info_['subject_id'] == i,'dob'].item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45d52bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "output[['subject_id','Bars', 'Bars_Speech', 'Samples_no', 'Diagnosis','Prob_AT_tf_grad', 'Bars_Speech_pred_t','Bars_Total_pred_t']].head(200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a08312",
   "metadata": {},
   "source": [
    "output.to_csv('/home/kvattis/Desktop/BiogenSca_outputs_2022_04_22.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35519c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_sca1 = output[output['Diagnosis'] == 1]\n",
    "output_sca2 = output[output['Diagnosis'] == 2]\n",
    "output_sca3 = output[output['Diagnosis'] == 3]\n",
    "output_c = output[output['Diagnosis'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161de110",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3697338d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.scatter(output_c['Bars_Speech'], output_c['Prob_AT_tf_grad'], c = 'b' , marker = 'x')\n",
    "ax.scatter(output_sca1['Bars_Speech'], output_sca1['Prob_AT_tf_grad'], c = 'k' , marker = 'x')\n",
    "ax.scatter(output_sca2['Bars_Speech'], output_sca2['Prob_AT_tf_grad'], c = 'g' , marker = 'x')\n",
    "ax.scatter(output_sca3['Bars_Speech'], output_sca3['Prob_AT_tf_grad'], c = 'r' , marker = 'x')\n",
    "plt.xlim([-0.2, 4])\n",
    "plt.ylim([-0.05, 1.05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68186cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "plt.plot([0,4],[0,4])\n",
    "\n",
    "ax.scatter(output_sca1['Bars_Speech'], output_sca1['Bars_Speech_pred_t'], c = 'k' , marker = 'x')\n",
    "ax.scatter(output_sca2['Bars_Speech'], output_sca2['Bars_Speech_pred_t'], c = 'g' , marker = 'x')\n",
    "ax.scatter(output_sca3['Bars_Speech'], output_sca3['Bars_Speech_pred_t'], c = 'r' , marker = 'x')\n",
    "ax.scatter(output_c['Bars_Speech'], output_c['Bars_Speech_pred_t'], c = 'b' , marker = 'x')\n",
    "\n",
    "plt.xlim([-0.2, 4])\n",
    "plt.ylim([-0.05, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e64739",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "plt.plot([0,30],[0,30])\n",
    "ax.scatter(output_c['Bars'], output_c['Bars_Total_pred_t'], c = 'b' , marker = 'x')\n",
    "ax.scatter(output_sca1['Bars'], output_sca1['Bars_Total_pred_t'], c = 'k' , marker = 'x')\n",
    "ax.scatter(output_sca2['Bars'], output_sca2['Bars_Total_pred_t'], c = 'g' , marker = 'x')\n",
    "ax.scatter(output_sca3['Bars'], output_sca3['Bars_Total_pred_t'], c = 'r' , marker = 'x')\n",
    "plt.xlim([-0.2, 30])\n",
    "plt.ylim([-0.05, 30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8735db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "output[['subject_id','Bars', 'Bars_Speech', 'Samples_no', 'Diagnosis','Prob_AT_tf_grad', 'Bars_Speech_pred_t','Bars_Total_pred_t']].head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75a8243",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c80945",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_ = output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da84f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_agg = output.groupby(['subject_id'], as_index = False).median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ca5f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de22a191",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_agg.loc[output_agg['Diagnosis'] > 0,'Label_true'] = 1\n",
    "output_agg.loc[output_agg['Diagnosis'] == 0,'Label_true'] = 0\n",
    "output_agg.loc[output_agg['Prob_AT_tf_grad'] > 0.6,'Label_pred'] = 1\n",
    "output_agg.loc[output_agg['Prob_AT_tf_grad'] <= 0.6,'Label_pred'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6953ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801cedd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(output_agg['Label_true'].to_numpy(), output_agg['Label_pred'].to_numpy(), average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d22e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(output_agg['Label_true'].to_numpy(),output_agg['Prob_AT_tf_grad'].to_numpy(),average = 'weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b4340f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(output_agg['Bars_Speech'].to_numpy(), output_agg['Bars_Speech_pred_t'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a377572a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(output_agg['Bars'].to_numpy(), output_agg['Bars_Total_pred_t'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d8cbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(output_agg['subject_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b29122",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07234e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#survey_lex = pd.read_csv(data_home_dir + 'Biogen_SCA_Speech_Data/' + 'surveylex_questionIDs.csv',encoding='latin1')\n",
    "survey_lex = pd.read_excel(data_home_dir_at + 'Remote_AT_Speech_Data/' + 'surveylex_questionIDs.xlsx',engine='openpyxl')\n",
    "taskslist = survey_lex['question'].unique()\n",
    "#output_at = pd.DataFrame(columns = ['Date','subject_id','Neuropheno_ID','Bars','Bars_Speech','Sex','Diagnosis','DoB','Samples_no','Prob_AT_tf_grad', 'Bars_Speech_pred_t','Bars_Total_pred_t'])\n",
    "output_at = pd.DataFrame(columns = ['Date','subject_id','Neuropheno_ID','Diagnosis','Samples_no','Prob_AT_tf_grad', 'Bars_Speech_pred_t','Bars_Total_pred_t'])\n",
    "                                            \n",
    "for tt in  taskslist: \n",
    "    if tt not in [\"la_la_la\",\"go_go_go\",\"me_me_me\", \"lalala\", \"gogogo\", \"mememe\",\"papapa\"]:\n",
    "        continue\n",
    "    print(tt)\n",
    "    pd.set_option('display.max_columns', 4)\n",
    "    np.dtype(np.int16)\n",
    "    task = str(tt)\n",
    "    task_dir = str(tt)\n",
    "    \n",
    "    study_name = 'Remote_AT_Speech_Data'\n",
    "    study_dir = data_home_dir_at + 'Remote_AT_Speech_Data/'\n",
    "    survey_lex = pd.read_excel(study_dir + 'surveylex_questionIDs.xlsx',engine='openpyxl')\n",
    "\n",
    "    survey_response_A_7 = pd.read_excel(study_dir + 'surveyA_7_responses_summary.xlsx',engine='openpyxl')\n",
    "    survey_response_A_8_13 = pd.read_excel(study_dir + 'surveyA_8_13_responses_summary.xlsx',engine='openpyxl')\n",
    "    survey_response_A_14 = pd.read_excel(study_dir + 'surveyA_14_responses_summary.xlsx',engine='openpyxl')\n",
    "    survey_response_B_7 = pd.read_excel(study_dir + 'surveyB_7_responses_summary.xlsx',engine='openpyxl')\n",
    "    survey_response_B_8_13 = pd.read_excel(study_dir + 'surveyB_8_13_responses_summary.xlsx',engine='openpyxl')\n",
    "    survey_response_B_14 = pd.read_excel(study_dir + 'surveyB_14_responses_summary.xlsx',engine='openpyxl')\n",
    "    survey_response_C_7 = pd.read_excel(study_dir + 'surveyC_7_responses_summary.xlsx',engine='openpyxl')\n",
    "    survey_response_C_8_13 = pd.read_excel(study_dir + 'surveyC_8_13_responses_summary.xlsx',engine='openpyxl')\n",
    "    #survey_response_C_14 = pd.read_excel(study_dir + 'surveyC_14_responses_summary.xlsx',engine='openpyxl')\n",
    "    survey_response = pd.concat([survey_response_A_7, survey_response_A_8_13, survey_response_A_14, survey_response_B_7, survey_response_B_8_13, survey_response_B_14, survey_response_C_7, survey_response_C_8_13], ignore_index=True)\n",
    "\n",
    "    survey_submissions_A_7 = pd.read_excel(study_dir + 'surveyA_7_submissions_summary.xlsx',engine='openpyxl')\n",
    "    survey_submissions_A_8_13 = pd.read_excel(study_dir + 'surveyA_8_13_submissions_summary.xlsx',engine='openpyxl')\n",
    "    survey_submissions_A_14 = pd.read_excel(study_dir + 'surveyA_14_submissions_summary.xlsx',engine='openpyxl')\n",
    "    survey_submissions_B_7 = pd.read_excel(study_dir + 'surveyB_7_submissions_summary.xlsx',engine='openpyxl')\n",
    "    survey_submissions_B_8_13 = pd.read_excel(study_dir + 'surveyB_8_13_submissions_summary.xlsx',engine='openpyxl')\n",
    "    survey_submissions_B_14 = pd.read_excel(study_dir + 'surveyB_14_submissions_summary.xlsx',engine='openpyxl')\n",
    "    survey_submissions_C_7 = pd.read_excel(study_dir + 'surveyC_7_submissions_summary.xlsx',engine='openpyxl')\n",
    "    survey_submissions_C_8_13 = pd.read_excel(study_dir + 'surveyC_8_13_submissions_summary.xlsx',engine='openpyxl')\n",
    "    #survey_submissions_C_14 = pd.read_excel(study_dir + 'surveyC_14_submissions_summary.xlsx',engine='openpyxl')\n",
    "    survey_submissions = pd.concat([survey_submissions_A_7, survey_submissions_A_8_13, survey_submissions_A_14, survey_submissions_B_7, survey_submissions_B_8_13, survey_submissions_B_14, survey_submissions_C_7, survey_submissions_C_8_13], ignore_index=True)\n",
    "\n",
    "    \n",
    "#     Patient_info = pd.read_csv(study_dir + 'Subjects_Remote_Behavior.csv',encoding='latin1')\n",
    "#     Patient_info_ = Patient_info.loc[:,['subject_id','neuropheno_id','Diagnosis_1']]\n",
    "#     Patient_info_['Diagnosis_1'] = Patient_info_['Diagnosis_1'].apply(lambda x: 0 if x == 'Control' else 1)\n",
    "#     Patient_info_ = Patient_info_.rename(columns={\"Diagnosis_1\": \"diagnosis\"})\n",
    "\n",
    "    Patient_info = pd.read_csv('/home/kvattis/Desktop/Subjects_Remote_Behavior_AT.csv',encoding='latin1')\n",
    "    Patient_info_ = Patient_info.loc[:,['subject_id','Neuropheno Study Link','diagnosis']] \n",
    "    Patient_info_['diagnosis'] = Patient_info_['diagnosis'].apply(lambda x: 0 if x == 'Control' else 1)\n",
    "    Patient_info_ = Patient_info_.rename(columns={\"diagnosis\": \"diagnosis\", \"Neuropheno Study Link\" : 'neuropheno_id'})\n",
    "    \n",
    "    survey_lex_ = survey_lex.loc[:,['questionId','question']]\n",
    "    survey_response_ = survey_response.loc[:,['sampleId','questionId', 'sessionId','createdDate']]\n",
    "    survey_response_['createdDate'] = survey_response_['createdDate'].apply(lambda x: x[0:4] + '_' + x[5:7] + '_' + x[8:10] )\n",
    "    survey_submissions_ = survey_submissions.loc[:,['sessionId','Your participant ID:']]\n",
    "    survey_submissions_ = survey_submissions_.rename(columns={\"Your participant ID:\": \"subject_id\"})\n",
    "    df = pd.merge(pd.merge(pd.merge(survey_response_,survey_lex_,on='questionId'), survey_submissions_, on = 'sessionId'),Patient_info_, on = 'subject_id')\n",
    "    df.dropna(subset = [\"sampleId\"], inplace=True)\n",
    "    df_task = df.loc[df['question'] == task][['sampleId','subject_id','neuropheno_id','diagnosis','createdDate']]\n",
    "    df_task_numpy = df_task.to_numpy()\n",
    "        \n",
    "    list_diagnostic = ['Control', 'Ataxia', 'MSA', 'Other']\n",
    "\n",
    "    \n",
    "    #Going over all the files for the task\n",
    "    list_names = []\n",
    "    for entry in df_task_numpy:\n",
    "        #print(entry)\n",
    "        file_name = entry[0]\n",
    "        ID = str(entry[1])\n",
    "\n",
    "        if  not (pd.isnull(entry[2]) or entry[2] == 'NAN'):\n",
    "            Neur_phen_id = str(int(entry[2]))\n",
    "        else:\n",
    "            Neur_phen_id = ID\n",
    "        \n",
    "        if int(Neur_phen_id) == 20094:\n",
    "            continue\n",
    "            \n",
    "        if int(Neur_phen_id) in IDs_used:\n",
    "            continue\n",
    "        \n",
    "        diagn = entry[3]\n",
    "        date = entry[4]\n",
    "        Date = date[:4] + date[5:7] + date[8:]\n",
    "#         bars_total = (entry[5] + entry[6])/2.\n",
    "#         bars_speech = (entry[7] + entry[8])/2./10.\n",
    "#         sex = entry[9]\n",
    "        #age = entry[10]\n",
    "        \n",
    "        path_to_file = study_dir + ID + '_' + date + '*_A/' + file_name + '.wav'\n",
    "        path_to_file_flag = 0        \n",
    "        \n",
    "        #if os.path.exists(path_to_file):\n",
    "        file_ = glob.glob(path_to_file)\n",
    "        if file_: \n",
    "            path_to_file_flag = 1\n",
    "            path_to_file = file_[0]\n",
    "        \n",
    "        if path_to_file_flag == 0:\n",
    "            path_to_file = study_dir + ID + '_' + date + '*_B/' + file_name + '.wav'\n",
    "            file_ = glob.glob(path_to_file)\n",
    "            if file_: \n",
    "                path_to_file_flag = 1\n",
    "                path_to_file = file_[0]\n",
    "        \n",
    "        if path_to_file_flag == 0:\n",
    "            path_to_file = study_dir + ID + '_' + date + '*_C*/' + file_name + '.wav'\n",
    "            file_ = glob.glob(path_to_file)\n",
    "            if file_: \n",
    "                path_to_file_flag = 1\n",
    "                path_to_file = file_[0]\n",
    "            \n",
    "        if path_to_file_flag == 0:\n",
    "            path_to_file = study_dir + ID + '_' + date + '*_D/' + file_name + '.wav'\n",
    "            file_ = glob.glob(path_to_file)\n",
    "            if file_: \n",
    "                path_to_file_flag = 1\n",
    "                path_to_file = file_[0]  \n",
    "        \n",
    "        if path_to_file_flag == 0: continue;\n",
    "            \n",
    "        #Assign label\n",
    "        if diagn == 0:\n",
    "            #diagn = 'Control'\n",
    "            label = 0\n",
    "        elif diagn == 1:\n",
    "            #diagn = 'Ataxia'\n",
    "            label = 1\n",
    "        elif diagn == 2:\n",
    "            #diagn = 'Ataxia'\n",
    "            label = 1\n",
    "        elif diagn == 3:\n",
    "            #diagn = 'Ataxia'\n",
    "            label = 1\n",
    "        elif diagn == 7:\n",
    "            #diagn = 'MSA'\n",
    "            label = 7\n",
    "        else:\n",
    "            #diagn = 'Other'\n",
    "            label = 5\n",
    "        \n",
    "        if label not in [0,1]:\n",
    "            continue\n",
    "        \n",
    "        if label == 0:\n",
    "            bars_total = 0\n",
    "            bars_speech = 0 \n",
    "\n",
    "        if Neur_phen_id == ID:\n",
    "            no_samples = speech_analyzer.load(path_to_file,ID)\n",
    "            Neur_phen_id = None\n",
    "        else:\n",
    "            no_samples = speech_analyzer.load(path_to_file,Neur_phen_id)\n",
    "        \n",
    "        if no_samples == 0: \n",
    "            continue\n",
    "            \n",
    "#         output_at = output_at.append({'Date' : Date, 'subject_id' : ID, 'Neuropheno_ID' : Neur_phen_id, 'Bars': bars_total, 'Bars_Speech':bars_speech, 'Sex': sex, 'Diagnosis': diagn,'Samples_no' : speech_analyzer.sample_size_s, 'Prob_AT_tf_grad': speech_analyzer.classify(),\n",
    "#                                'Bars_Speech_pred_t': speech_analyzer.BARS_speech(), 'Bars_Total_pred_t': speech_analyzer.BARS_total()}, \n",
    "#                 ignore_index = True)\n",
    "\n",
    "        output_at = output_at.append({'Date' : Date, 'subject_id' : ID, 'Neuropheno_ID' : Neur_phen_id, 'Diagnosis': diagn,'Samples_no' : speech_analyzer.sample_size_s, 'Prob_AT_tf_grad': speech_analyzer.classify(),\n",
    "                               'Bars_Speech_pred_t': speech_analyzer.BARS_speech(), 'Bars_Total_pred_t': speech_analyzer.BARS_total()}, \n",
    "                ignore_index = True)\n",
    "        \n",
    "output_at = output_at.astype(float).groupby(['Date','subject_id'], as_index = False).median().sort_values(by=['subject_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521147c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_at.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab46dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2460f360",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_at[['subject_id', 'Samples_no', 'Diagnosis','Prob_AT_tf_grad', 'Bars_Speech_pred_t','Bars_Total_pred_t']].head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b7d02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_at[['Diagnosis','Prob_AT_tf_grad']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ae9e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_at_agg = output_at.groupby(['subject_id'], as_index = False).median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99344e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_at_agg['Label_true'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb97d45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_agg['Label_true'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf816339",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_at_agg.loc[output_at_agg['Diagnosis'] > 0,'Label_true'] = 1\n",
    "output_at_agg.loc[output_at_agg['Diagnosis'] == 0,'Label_true'] = 0\n",
    "output_at_agg.loc[output_at_agg['Prob_AT_tf_grad'] > 0.6,'Label_pred'] = 1\n",
    "output_at_agg.loc[output_at_agg['Prob_AT_tf_grad'] <= 0.6,'Label_pred'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499aedfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(output_at_agg['Label_true'].to_numpy(), output_at_agg['Label_pred'].to_numpy(), average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4864f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(output_at_agg['Label_true'].to_numpy(),output_at_agg['Prob_AT_tf_grad'].to_numpy(),average = 'weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f465d915",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(output_at[['Label_true','Label_pred']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d87224",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(output[['Label_true','Label_pred']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0607b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_agg.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8659a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_at_agg.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46007205",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_at_agg.loc[output_at_agg['Diagnosis'] > 0,'Bars'] = np.nan\n",
    "output_at_agg.loc[output_at_agg['Diagnosis'] == 0,'Bars'] = 0\n",
    "output_at_agg.loc[output_at_agg['Diagnosis'] > 0,'Bars_Speech'] = np.nan\n",
    "output_at_agg.loc[output_at_agg['Diagnosis'] == 0,'Bars_Speech'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b8b8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    " output_merged = pd.concat([output_agg[['Label_true','Label_pred','Prob_AT_tf_grad','Bars','Bars_Speech','Bars_Speech_pred_t', 'Bars_Total_pred_t']],output_at_agg[['Label_true','Label_pred','Prob_AT_tf_grad','Bars','Bars_Speech','Bars_Speech_pred_t', 'Bars_Total_pred_t']]],ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe37c299",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(output_merged['Label_true'].to_numpy(), output_merged['Label_pred'].to_numpy(), average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41acf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(output_merged['Label_true'].to_numpy(),output_merged['Prob_AT_tf_grad'].to_numpy(),average = 'weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3e9baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_merged_filt = output_merged[~output_merged['Bars_Speech'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c1a518",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(output_merged_filt['Bars_Speech'].to_numpy(), output_merged_filt['Bars_Speech_pred_t'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7bb4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(output_merged_filt['Bars'].to_numpy(), output_merged_filt['Bars_Total_pred_t'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a023be1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74755308",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(output_merged_filt['Bars_Speech'].to_numpy(), output_merged_filt['Bars_Speech_pred_t'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f393c51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(output_merged_filt['Bars'].to_numpy(), output_merged_filt['Bars_Total_pred_t'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7393f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_merged_filt[output_merged_filt['Label_true'] == 1]['Bars_Speech'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd3881d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_merged['Label_true'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b47635",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_merged[['Label_true','Label_pred']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886b1fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "taskslist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cb0e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(output_at['subject_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af02f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.scatter(output_merged[output_merged['Label_true'] == 0]['Bars_Speech'], output_merged[output_merged['Label_true'] == 0]['Prob_AT_tf_grad'], c = 'b' , marker = 'x')\n",
    "ax.scatter(output_merged[output_merged['Label_true'] == 1]['Bars_Speech'], output_merged[output_merged['Label_true'] == 1]['Prob_AT_tf_grad'], c = 'r' , marker = 'x')\n",
    "plt.ylim([-0.05, 1.05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15707a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.scatter(output_merged_filt[output_merged_filt['Label_true'] == 0]['Bars_Speech'], output_merged_filt[output_merged_filt['Label_true'] == 0]['Bars_Speech_pred_t'], c = 'b' , marker = 'x')\n",
    "ax.scatter(output_merged_filt[output_merged_filt['Label_true'] == 1]['Bars_Speech'], output_merged_filt[output_merged_filt['Label_true'] == 1]['Bars_Speech_pred_t'], c = 'r' , marker = 'x')\n",
    "plt.plot([0,4],[0,4])\n",
    "#plt.ylim([-0.05, 1.05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061acb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.scatter(output_merged_filt[output_merged_filt['Label_true'] == 0]['Bars'], output_merged_filt[output_merged_filt['Label_true'] == 0]['Bars_Total_pred_t'], c = 'b' , marker = 'x')\n",
    "ax.scatter(output_merged_filt[output_merged_filt['Label_true'] == 1]['Bars'], output_merged_filt[output_merged_filt['Label_true'] == 1]['Bars_Total_pred_t'], c = 'r' , marker = 'x')\n",
    "plt.plot([0,30],[0,30])\n",
    "#plt.ylim([-0.05, 1.05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02117040",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
